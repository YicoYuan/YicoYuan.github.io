<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>RNA-seq背景知识</title>
    <url>/2022/02/12/RNA-seq-01/</url>
    <content><![CDATA[<p>RNA-seq利用NGS测序技术来分析生物样品转录组，以揭示其RNA在某个时刻的表达情况及表达量。其原理如下图所示：</p>
<p><img src="/2022/02/12/RNA-seq-01/01.png"></p>
<span id="more"></span>

<p>生物组织内，基因被转录和剪切产生成熟的mRNA转录本（红色）。从组织中提取出mRNA，随机打断成片段，然后反转录为ds-cDNA（蓝色）。ds-cDNA通过高通量短读长方法进行测序。然后将测序得到的序列与参考基因组进行比对。比对得到的数据就可以用来分析基因的表达情况、相对表达量以及可变剪接。</p>
<p>RNA-seq能够识别基因可变剪接的转录本，转录后修饰，基因融合，SNP，基因不同的时期的表达水平，以及基因表达在不同组织或不同处理间的表达差异。除了mRNA，RNA-seq还可以识别不同类型的RNA。RNA-seq也可以用来测定外显子和内含子的边界，以确认或修缮之间注释的基因5’和3’的边界。单细胞测序是目前RNA-seq的前沿技术。</p>
<p>在RNA-seq之前，转录组的研究有基于杂交技术的基因芯片（microarray）、基于序列分析的基因表达系列分析（SAGE）和大规模平行信号测序系统（MASS）。Microarray是最早开发的高通量转录组检测技术。该技术成本适中，整个方法较为成熟。但是该技术只限用于已知序列，无法检测新的RNA；灵敏度有限，难以检测低丰度的目标和重复序列；很难检测出融合基因、多顺反子等异常转录产物。SAGE不需要任何基因序列信息，能够全局性的检测所有基因的表达水平；MPSS是对SAGE的改进，它简化了测序过程，提高了精度。但两者都是基于昂贵的Sanger测序，需要大量的测序工作，技术难度大，而且涉及酶切、PCR扩增、克隆等可能会产生碱基偏向性的步骤，因此限制其推广。</p>
<p>相比之下，RNA-seq具有诸多独特的优势：</p>
<ul>
<li>数字化信号。每个转录本片段单个核苷酸分辨率，可以检测单个碱基差异、基因家族中相似基因以及可变剪接造成的不同的转录本。不存在传统microarray荧光模拟信号带来的交叉反应和背景噪音问题。</li>
<li>高灵敏度。能够检测到细胞中低表达的转录本。</li>
<li>转录组分析。无需预先设计特异性探针，能够直接对任何物种进行转录组分析，这对非模式生物的研究尤为重要。同时能够检测未知基因，发现新的转录本，并精确地识别可变剪接位点、SNP及UTR区域。</li>
<li>更广的检测范围和更少的样品检测量。</li>
</ul>
<h1 id="RNA-seq测序方法"><a href="#RNA-seq测序方法" class="headerlink" title="RNA-seq测序方法"></a>RNA-seq测序方法</h1><p><img src="/2022/02/12/RNA-seq-01/02.png"></p>
<h1 id="RNA-seq数据分析流程"><a href="#RNA-seq数据分析流程" class="headerlink" title="RNA-seq数据分析流程"></a>RNA-seq数据分析流程</h1><p><img src="/2022/02/12/RNA-seq-01/03.jpg"></p>
<p><img src="/2022/02/12/RNA-seq-01/04.png" alt="DGE"></p>
<h2 id="测序reads的比对和组装"><a href="#测序reads的比对和组装" class="headerlink" title="测序reads的比对和组装"></a>测序reads的比对和组装</h2><p>测序完成后，分析的起点是包含测序碱基的FASTQ文件。通常第一步是将测序reads比对到已知的转录组（或注释的基因组），将每个reads转换为基因组坐标。常用的比对工具有TopHat、STAR和HISAT，其都依赖于参考基因组的存在。由于测序的cDNA来自RNA，可能跨越外显子边界，因此与基因组测序不同的是，转录组测序在与参考基因组比对时需进行剪接比对，即允许reads中出现大片段gap。</p>
<p>如果没有包含已知外显子边界的高质量基因组注释，或者如果希望将reads与转录本（而不是基因）相关联，则需要在比对后执行转录组组装步骤。诸如StringTie和SOAPdenovo-Trans之类的组装工具使用比对reads的gap来推测外显子边界和可能的剪接位点。转录本重头组装特别适合用于参考基因组注释缺失或不完整的物种，或者对异转录本感兴趣的研究中。但是，通常从有参考基因组的RNA-seq中获取DGE不需要进行从头组装转录本。</p>
<p>最近，涌现了一些计算效率高的alignment-free工具，例如Salmon和Kallisto。它们会在一步操作中组装转录本并对其进行定量。这些工具在定量高丰度转录本方面表现良好，但是在定量低丰度或短转录本方面不够准确。</p>
<p>不同的比对工具分配ambiguous reads的策略会影响最后的表达量估计。尤其是存在multimap的reads时，对结果的影响尤为明显。因此对于如何正确处理比对到多个位置的reads，仍是RNA-seq数据分析中一个重点领域。目前一种常见的做法是在定量前过滤掉这些reads，但是这也可能导致结果产生偏差。</p>
<h2 id="基因-转录本丰度定量"><a href="#基因-转录本丰度定量" class="headerlink" title="基因/转录本丰度定量"></a>基因/转录本丰度定量</h2><p>将reads比对到基因组或转录组后，下一步就是将它们分配给基因或转录本，获得表达矩阵。单个基因的表达量是计算与已知基因重叠的reads数。但是，把短reads分配到特定的转录异变体（同一个基因因可变剪接产生的不同mRNA）则需要统计模型估计，尤其是很多reads不跨越剪接点。即使是在仅研究基因表达差异的情况下，定量转录本也会获得更准确的结果，尤其是基因在不同条件下表达不同长度的转录本时。例如，如果某个基因的一个转录本在A样品中的长度是B样品中的一半，但是表达速率却是后者两倍，则单纯基于基因的定量无法检测到这一基因的差异表达。</p>
<p>常用的定量工具包括，RSEM、CuffLinks、MMSEQ、HTSeq和featureCounts，以及上述alignment-free的Salmon等工具。基于比对结果计数的工具（例如HTSeq和featureCounts）通常会丢弃许多比对的序列，包括multimap或overlap的reads。RSEM使用期望最大化来分配模糊的reads，alignment-free的定量工具则将这些模糊的reads包括在它们相应的转录本计数中，这可能导致结果有偏差。使用tximport可以将转录本丰度转换成等效的reads数。量化后会得到一个合并的表达矩阵，矩阵的第一列为每个表达特征（基因/转录本），其后每列为每个样品的表达值，该表达值是实际的reads数。</p>
<h2 id="过滤和标准化"><a href="#过滤和标准化" class="headerlink" title="过滤和标准化"></a>过滤和标准化</h2><p>通常，基因或转录本的reads数需要进行过滤和标准化，以减少测序深度、表达模式和技术偏差带来的影响。过滤掉在所有样本中都低丰度表达的基因是一种很直接的方式，并且已经证明可以改善对真正差异表达基因的检测。表达矩阵的标准化的方法较为复杂。</p>
<p>研究表明，标准化方法的选择可能对最终结果和生物学结论有重要影响。大多数标准化算法依赖于两个重要假设：一、大多数基因的表达水平在生物重复中变化不大。二、不同的样本组总的mRNA水平没有显著差异。但是当上述假设不成立时，如一些基因在一个样品中高表达，而在同组另一个样品中正常表达，则简单使用RPKM标准化是不合适的，因为相同数目的reads会分配到在第二个样本里更多的基因上。而标准化的方法如edgeR所使用的M-值的加权截断均值（TMM）就能解决这个问题。</p>
<h2 id="差异表达的统计建模"><a href="#差异表达的统计建模" class="headerlink" title="差异表达的统计建模"></a>差异表达的统计建模</h2><p>获得表达矩阵后，就可以构建统计模型评估哪些转录本表达发生了显著的改变。有几个常用工具可以完成此任务，可分为基于基因水平计数和基于转录本水平计数。基因水平的工具通常依赖于比对的reads数，并使用广义线性模型来进行复杂实验设计的评估。这些工具包括edgeR、DESeq2和limma+voom等，这些工具计算效率高且工具之间结果稳定性好。评估差异转录本的工具包括CuffDiff、MMSEQ和Ballgown，往往需要更多的计算资源，且结果变化也更大。</p>
<h2 id="差异表达基因注释"><a href="#差异表达基因注释" class="headerlink" title="差异表达基因注释"></a>差异表达基因注释</h2><h3 id="基因功能富集分析"><a href="#基因功能富集分析" class="headerlink" title="基因功能富集分析"></a>基因功能富集分析</h3><h3 id="基因集富集分析（GSEA）"><a href="#基因集富集分析（GSEA）" class="headerlink" title="基因集富集分析（GSEA）"></a>基因集富集分析（GSEA）</h3><h3 id="基因集变异分析（GSVA）"><a href="#基因集变异分析（GSVA）" class="headerlink" title="基因集变异分析（GSVA）"></a>基因集变异分析（GSVA）</h3><h3 id="蛋白质互作分析（PPI）"><a href="#蛋白质互作分析（PPI）" class="headerlink" title="蛋白质互作分析（PPI）"></a>蛋白质互作分析（PPI）</h3><h3 id="转录因子分析"><a href="#转录因子分析" class="headerlink" title="转录因子分析"></a>转录因子分析</h3><h3 id="加权基因共表达网络分析（WGCNA）"><a href="#加权基因共表达网络分析（WGCNA）" class="headerlink" title="加权基因共表达网络分析（WGCNA）"></a>加权基因共表达网络分析（WGCNA）</h3><p>参考文献：</p>
<ol>
<li><a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0881-8">A survey of best practices for RNA-seq data analysis</a></li>
<li><a href="https://www.nature.com/articles/s41576-019-0150-2">RNA sequencing: the teenage years</a></li>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0965174821001387">A whole transcriptomic approach provides novel insights into the molecular basis of organophosphate and pyrethroid resistance in <em>Anopheles arabiensis</em> from Ethiopia</a></li>
<li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0168945219300342">AtSPX1-mediated transcriptional regulation duringleaf senescence in Arabidopsis thaliana</a></li>
</ol>
]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
  </entry>
  <entry>
    <title>序列比对</title>
    <url>/2022/02/14/RNA-seq-03/</url>
    <content><![CDATA[<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">转录组常需要gff格式注释来识别外显子区域</span></span><br><span class="line">gffread ~/RNA_seq/01ref/Ppersica.gff3 -T -o ~/RNA_seq/01ref/Ppersica.gtf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">构建参考基因组索引</span></span><br><span class="line">STAR --runThreadN 20 \</span><br><span class="line">     --runMode genomeGenerate \</span><br><span class="line">     --genomeDir ~/RNA_seq/01ref/index_dir \</span><br><span class="line">     --genomeFastaFiles ~/RNA_seq/01ref/Ppersica.fa \</span><br><span class="line">     --sjdbGTFfile ~/RNA_seq/01ref/Ppersica.gtf \</span><br><span class="line">     --sjdbOverhang 124</span><br><span class="line">     </span><br><span class="line"><span class="meta">#</span><span class="bash">--runThreadN:线程数</span></span><br><span class="line"><span class="meta">#</span><span class="bash">--runMode：运行模式</span></span><br><span class="line"><span class="meta">#</span><span class="bash">--genomeDir：索引文件输出目录（需提前建立）</span></span><br><span class="line"><span class="meta">#</span><span class="bash">--genomeFastaFiles：基因组fasta文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash">--sjdbGTFfile：GTF注释文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash">--sjdbOverhang：reads长度减1。主要用于可变剪接的预测。</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">序列比对</span></span><br><span class="line">for i in SRR74106&#123;82..90&#125;</span><br><span class="line">do</span><br><span class="line">STAR --genomeDir ~/RNA_seq/01ref/index_dir \</span><br><span class="line">     --readFilesIn ~/RNA_seq/03clean/$&#123;i&#125;_1.fastq.gz ~/RNA_seq/03clean/$&#123;i&#125;_2.fastq.gz \</span><br><span class="line">     --readFilesCommand zcat \</span><br><span class="line">     --outFileNamePrefix ~/RNA_seq/04align/$i \</span><br><span class="line">     --runThreadN 20 \</span><br><span class="line">     --sjdbOverhang 124 \</span><br><span class="line">     --outSAMtype BAM SortedByCoordinate \</span><br><span class="line">     --outBAMsortingThreadN 5 \</span><br><span class="line">     --quantMode TranscriptomeSAM GeneCounts \</span><br><span class="line">     --twopassMode Basic</span><br><span class="line"> done     </span><br></pre></td></tr></table></figure>

<p>比对后的输出文件如下：</p>
<p><img src="/2022/02/14/RNA-seq-03/01.png"></p>
<p>使用multiqc对比对结果质控：</p>
]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
  </entry>
  <entry>
    <title>转录组测序数据及参考基因组准备</title>
    <url>/2022/02/13/RNA-seq-02/</url>
    <content><![CDATA[<h3 id="项目文件夹"><a href="#项目文件夹" class="headerlink" title="项目文件夹"></a>项目文件夹</h3><p>首先，建立一个项目所需的文件夹：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir ~/RNA_seq</span><br><span class="line">cd ~/RNA_seq</span><br><span class="line">mkdir &#123;01ref,02raw,03clean,04align,05quantification,06diff&#125;</span><br></pre></td></tr></table></figure>

<p>目录结构如下：</p>
<p><img src="/2022/02/13/RNA-seq-02/01.png"></p>
<h3 id="参考基因组"><a href="#参考基因组" class="headerlink" title="参考基因组"></a>参考基因组</h3><p>我们使用JGI的<a href="https://phytozome-next.jgi.doe.gov/">phytozome</a>植物基因组数据库下载peach(<em>prunus persica</em>)的参考基因组和注释文件。勾选所需的参考基因组和注释文件后，点击download，官方提供了浏览器下载和命令行下载两种方式。</p>
<p><img src="/2022/02/13/RNA-seq-02/02.png"></p>
<h3 id="测序数据"><a href="#测序数据" class="headerlink" title="测序数据"></a>测序数据</h3><p>测序数据来源于这篇<a href="https://www.sciencedirect.com/science/article/abs/pii/S0378111918308138">文献</a>。NCBI搜索<a href="https://www.ncbi.nlm.nih.gov/sra?linkname=bioproject_sra_all&from_uid=477414">PRJNA477414</a>，然后选择send to run selector，下载Accession List，其内容为SRR号：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SRR7410682</span><br><span class="line">SRR7410683</span><br><span class="line">SRR7410684</span><br><span class="line">SRR7410685</span><br><span class="line">SRR7410686</span><br><span class="line">SRR7410687</span><br><span class="line">SRR7410688</span><br><span class="line">SRR7410689</span><br><span class="line">SRR7410690</span><br></pre></td></tr></table></figure>

<p>按官网说明安装sra toolkit工具。先使用prefetch将sra下载到本地，然后fastq-dump将sra转换为fastq格式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prefetch --option-file SRR_Acc_List.txt</span><br><span class="line"></span><br><span class="line">while read id</span><br><span class="line">do</span><br><span class="line">nohup fastq-dump -O ~/RNA_seq/02raw --gzip --split-3 --readids $id &amp;</span><br><span class="line">done &lt; SRR_Acc_List.txt</span><br></pre></td></tr></table></figure>

<p>测序数据如下：</p>
<p><img src="/2022/02/13/RNA-seq-02/03.png"></p>
<h3 id="测序数据质控"><a href="#测序数据质控" class="headerlink" title="测序数据质控"></a>测序数据质控</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">原始数据qc报告</span></span><br><span class="line">for i in SRR74106&#123;82..90&#125;</span><br><span class="line">do </span><br><span class="line">fastqc -t 20 -o ~/RNA_seq/02raw/qc ~/RNA_seq/02raw/$&#123;i&#125;_1.fastq.gz ~/RNA_seq/02raw/$&#123;i&#125;_2.fastq.gz</span><br><span class="line">done</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">合并qc报告到一个文件</span></span><br><span class="line">multiqc ~/RNA_seq/02raw/qc -o ~/RNA_seq/02raw/multiqc</span><br><span class="line"><span class="meta">#</span><span class="bash">可以看到duplicates很高，但是不用去除，因为难以区分duplicates是PCR引起的还是基因的高表达。</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">质量过滤：去掉adapter和低质量reads</span></span><br><span class="line">for i in SRR74106&#123;82..90&#125;</span><br><span class="line">do</span><br><span class="line">fastp -w 20 -f 10 -F 10 \</span><br><span class="line">	    -i ~/RNA_seq/02raw/$&#123;i&#125;_1.fastq.gz \</span><br><span class="line">	    -o ~/RNA_seq/03clean/$&#123;i&#125;_1.fastq.gz \</span><br><span class="line">	    -I ~/RNA_seq/02raw/$&#123;i&#125;_2.fastq.gz \</span><br><span class="line">	    -O ~/RNA_seq/03clean/$&#123;i&#125;_2.fastq.gz </span><br><span class="line">done</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
  </entry>
  <entry>
    <title>表达定量</title>
    <url>/2022/02/17/RNA-seq-04/</url>
    <content><![CDATA[<h3 id="如何区分RNA-seq数据来源是否基于链特异性建库"><a href="#如何区分RNA-seq数据来源是否基于链特异性建库" class="headerlink" title="如何区分RNA-seq数据来源是否基于链特异性建库"></a>如何区分RNA-seq数据来源是否基于链特异性建库</h3><p>双端测序中，根据read1和read2与DNA和RNA的比对情况，有三种类型的建库方式：</p>
<p><img src="/2022/02/17/RNA-seq-04/01.PNG"></p>
<ul>
<li>Condition A：如果read1与RNA序列一致，则称为stranded library。</li>
<li>Condition B：如果read2与RNA序列一致，则称为reversed stranded library。</li>
<li>Condition C：但如果read1和read2都存在与RNA序列一致的情况，则称为unstranded library。</li>
</ul>
<p>STAR比对中，如果设置了–quantMode为GeneCounts，则会输出一个ReadsPerGene.out.tab的文件，里面记录了比对到基因上的reads数。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENSG00000198804.2       555285  290702  281079</span><br><span class="line">ENSG00000198938.2       471151  238612  232541</span><br><span class="line">ENSG00000198886.2       466966  236203  230767</span><br><span class="line">ENSG00000210082.2       404889  203289  201602</span><br><span class="line">ENSG00000198712.1       359278  175022  184256</span><br><span class="line">ENSG00000198727.2       297601  150393  147574</span><br><span class="line">ENSG00000198763.3       288383  149779  138612</span><br><span class="line">ENSG00000156508.17      189858  96202   93663</span><br></pre></td></tr></table></figure>

<p>第二列：counts for unstranded RNA-seq（Condition C）</p>
<p>第三列：counts for stranded RNA-seq（Condition A）</p>
<p>第四列：counts for reverse stranded RNA-seq（Condition B）</p>
<p>如果是非链特异性建库，则第三列和第四列counts差不多。如果第4列为0，则是链特异性建库。如果第3列为0，则是reverse stranded。</p>
<h3 id="安装featureCounts"><a href="#安装featureCounts" class="headerlink" title="安装featureCounts"></a>安装featureCounts</h3><p>下载subreads最新<a href="https://sourceforge.net/projects/subread/">安装包</a>，解压后按readme文件操作，然后将bin文件增加至环境变量，即在用户根目录下的.bashrc文件中新增<code>export PATH=&quot;/home/yico/subread/bin:$PATH&quot;</code>。也可以使用conda直接安装。</p>
<h3 id="使用featurecounts"><a href="#使用featurecounts" class="headerlink" title="使用featurecounts"></a>使用featurecounts</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">featureCounts -T 20 -p --countReadPairs -s 0 \</span><br><span class="line">	-a ~/RNA_seq/01ref/Ppersica.gtf \</span><br><span class="line">	-o ~/RNA_seq/05quantification/reads_counts.txt \</span><br><span class="line">  ~/RNA_seq/04align/*sorted*.bam </span><br></pre></td></tr></table></figure>

<h3 id="使用multiqc质控"><a href="#使用multiqc质控" class="headerlink" title="使用multiqc质控"></a>使用multiqc质控</h3><p><img src="/2022/02/17/RNA-seq-04/02.png"></p>
<h3 id="提取基因原始表达值"><a href="#提取基因原始表达值" class="headerlink" title="提取基因原始表达值"></a>提取基因原始表达值</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">grep -v &#x27;^#&#x27; ~/RNA_seq/05quantification/reads_counts.txt | cut -f 2-6 --complement &gt; ~/RNA_seq/06diff/counts.txt</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>RNA-seq</category>
      </categories>
  </entry>
  <entry>
    <title>差异分析</title>
    <url>/2022/02/19/RNA-seq-05/</url>
    <content><![CDATA[<h3 id="构建表达矩阵"><a href="#构建表达矩阵" class="headerlink" title="构建表达矩阵"></a>构建表达矩阵</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#更改行名，字段按顺序排列，同时去除表达总量小于10的基因</span><br><span class="line">awk &#x27;BEGIN&#123;printf &quot;geneid\t105_1\t105_2\t105_3\t120_1\t120_2\t120_3\t135_1\t135_2\t135_3\n&quot;&#125;&#123;if($2+$3+$4+$5+$6+$7+$8+$9+$10&gt;=10)print $1,$6,$8,$9,$4,$5,$7,$2,$3,$NF&#125;&#x27; counts.txt &gt; deseq2_input.txt</span><br></pre></td></tr></table></figure>

<p>效果如下：</p>
<p><img src="/2022/02/19/RNA-seq-05/01.png" alt="before"></p>
<p><img src="/2022/02/19/RNA-seq-05/02.png" alt="after"></p>
<h3 id="差异分析"><a href="#差异分析" class="headerlink" title="差异分析"></a>差异分析</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#设置R工作目录</span><br><span class="line">setwd(&quot;/home/yico/RNA_seq/06diff&quot;)</span><br><span class="line"></span><br><span class="line">#加载R包</span><br><span class="line">library(DESeq2)</span><br><span class="line"></span><br><span class="line">#读取counts.txt数据</span><br><span class="line">countsTable &lt;- read.csv(&quot;~/RNA_seq/06diff/deseq2_input.txt&quot;, row.names=1, sep=&quot;&quot;)</span><br><span class="line"></span><br><span class="line">#更改数据行名</span><br><span class="line">sampleNames &lt;- c(&quot;105_1&quot;,&quot;105_2&quot;,&quot;105_3&quot;,&quot;120_1&quot;,&quot;120_2&quot;,&quot;120_3&quot;,&quot;135_1&quot;,&quot;135_2&quot;,&quot;135_3&quot;)</span><br><span class="line">colnames(countsTable) &lt;- sampleNames</span><br><span class="line"></span><br><span class="line">#建立样品分组信息</span><br><span class="line">countsDesign &lt;- data.frame(row.names=sampleNames,group=c(&quot;105&quot;,&quot;105&quot;,&quot;105&quot;,&quot;120&quot;,&quot;120&quot;,&quot;120&quot;,&quot;135&quot;,&quot;135&quot;,&quot;135&quot;))</span><br><span class="line"></span><br><span class="line">#将读入的数据由data.frame转换为matrix</span><br><span class="line">countsMatrix &lt;- as.matrix(countsTable)</span><br><span class="line"></span><br><span class="line">#将countsMatrix转换为DESeq2所需的数据格式,这一步包含了数据的归一化（构建dds）</span><br><span class="line">dds &lt;- DESeqDataSetFromMatrix(countsMatrix,colData=countsDesign,design=~group)</span><br><span class="line"></span><br><span class="line">#DESeq分析：大小因子估计，离差估计，负二项分布的拟合以及计算相应的统计量</span><br><span class="line">dds &lt;- DESeq(dds,parallel=T)</span><br><span class="line"></span><br><span class="line">#分别提取两两之间差异分析的结果</span><br><span class="line">res_105Vs120 &lt;- results(dds,contrast=c(&quot;group&quot;,105,120),parallel=T)</span><br><span class="line">res_105Vs135 &lt;- results(dds,contrast=c(&quot;group&quot;,105,135),parallel=T)</span><br><span class="line">res_120Vs135 &lt;- results(dds,contrast=c(&quot;group&quot;,120,135),parallel=T)</span><br><span class="line"></span><br><span class="line">#提取差异显著的基因及其中上调和下调基因</span><br><span class="line">resSig_105Vs120 &lt;-as.data.frame(subset(res_105Vs120,padj&lt;&quot;0.05&quot;))</span><br><span class="line">resSigUp_105Vs120 &lt;- as.data.frame(subset(res_105Vs120,padj&lt;&quot;0.05&quot;&amp;log2FoldChange&gt;&quot;1&quot;))</span><br><span class="line">resSigDown_105Vs120 &lt;- as.data.frame(subset(res_105Vs120,padj&lt;&quot;0.05&quot;&amp;log2FoldChange&lt;&quot;-1&quot;))</span><br><span class="line">resSig_105Vs135 &lt;- as.data.frame(subset(res_105Vs135,padj&lt;&quot;0.05&quot;))</span><br><span class="line">resSigUp_105Vs135 &lt;- as.data.frame(subset(res_105Vs135,padj&lt;&quot;0.05&quot;&amp;log2FoldChange&gt;&quot;1&quot;))</span><br><span class="line">resSigDown_105Vs135 &lt;- as.data.frame(subset(res_105Vs135,padj&lt;&quot;0.05&quot;&amp;log2FoldChange&lt;&quot;-1&quot;))</span><br><span class="line">resSig_120Vs135 &lt;- as.data.frame(subset(res_120Vs135,padj&lt;&quot;0.05&quot;))</span><br><span class="line">resSigUp_120Vs135 &lt;- as.data.frame(subset(res_120Vs135,padj&lt;&quot;0.05&quot;&amp;log2FoldChange&gt;&quot;1&quot;))</span><br><span class="line">resSigDown_120Vs135 &lt;- as.data.frame(subset(res_120Vs135,padj&lt;&quot;0.05&quot;&amp;log2FoldChange&lt;&quot;-1&quot;))</span><br></pre></td></tr></table></figure>

<h3 id="差异结果可视化"><a href="#差异结果可视化" class="headerlink" title="差异结果可视化"></a>差异结果可视化</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#加载R包</span><br><span class="line">library(ggplot2)</span><br><span class="line"></span><br><span class="line">#给显著差异的基因添加‘上调’、‘下调’和‘正常’的因子标签</span><br><span class="line">resSig_105Vs120$change &lt;- as.factor(ifelse( abs(resSig_105Vs120$log2FoldChange) &gt; 1,ifelse(resSig_105Vs120$log2FoldChange &gt; 1,&#x27;UP&#x27;,&#x27;DOWN&#x27;),&#x27;NON&#x27;))</span><br><span class="line"></span><br><span class="line">#绘制火山图</span><br><span class="line">volcano_105Vs120 &lt;- ggplot(resSig_105Vs120,aes(log2FoldChange,-log(padj,10),color=change))+geom_point()+scale_color_manual(values=c(&#x27;blue2&#x27;,&#x27;gray30&#x27;,&#x27;red2&#x27;))+theme(panel.grid=element_blank(),panel.background=element_rect(color=&#x27;black&#x27;,fill=&#x27;transparent&#x27;),legend.position=c(0.26,0.92))+theme(legend.position=&#x27;right&#x27;,legend.title=element_blank(),legend.key=element_rect(fill=&#x27;transparent&#x27;))+geom_vline(xintercept=c(-1,1),color=&#x27;gray&#x27;,size=0.25)+geom_hline(yintercept=-log(0.05,10),color=&#x27;gray&#x27;,size=0.25)+labs(x=&#x27;log2 Fold Change&#x27;,y=&#x27;-log10 p-value&#x27;,color=NA)+xlim(-5,5)</span><br><span class="line"></span><br><span class="line">#查看火山图</span><br><span class="line">volcano_105Vs120</span><br></pre></td></tr></table></figure>

<p>效果如下图：</p>
<p><img src="/2022/02/19/RNA-seq-05/03.png" alt="volcano plot"></p>
<h3 id="数据质量评估"><a href="#数据质量评估" class="headerlink" title="数据质量评估"></a>数据质量评估</h3>]]></content>
  </entry>
  <entry>
    <title>软件准备</title>
    <url>/2022/01/13/WES01/</url>
    <content><![CDATA[<h1 id="安装必备软件"><a href="#安装必备软件" class="headerlink" title="安装必备软件"></a>安装必备软件</h1><h2 id="Miniconda"><a href="#Miniconda" class="headerlink" title="Miniconda"></a>Miniconda</h2><h3 id="关于conda和miniconda"><a href="#关于conda和miniconda" class="headerlink" title="关于conda和miniconda"></a>关于conda和miniconda</h3><p>Conda is an open-source package management system and environment management system that runs on Windows, macOS, and Linux. Conda quickly installs, runs, and updates packages and their dependencies. Conda easily creates, saves, loads, and switches between environments on your local computer. It was created for Python programs but it can package and distribute software for any language.</p>
<p>Miniconda is a free minimal installer for conda. It is a small, bootstrap version of Anaconda that includes only conda, Python, the packages they depend on, and a small number of other useful packages, including pip, zlib and a few others. Use the <code>conda install</code> command to install 720+ additional conda packages from the Anaconda repository.</p>
<p>简单来说，conda是包和环境管理系统，用于安装软件包及其依赖关系，而miniconda是包含了conda的精简版，通过简单的conda install命令即可安装绝大多数生信所需软件，省去了软件安装和环境配置的麻烦。</p>
<span id="more"></span>

<h3 id="Installing-on-linux"><a href="#Installing-on-linux" class="headerlink" title="Installing on linux"></a>Installing on linux</h3><ol>
<li><p>Download the installer:</p>
<ul>
<li><a href="https://docs.conda.io/en/latest/miniconda.html#linux-installers">Miniconda installer for Linux</a>.</li>
</ul>
</li>
<li><p><a href="https://conda.io/projects/conda/en/latest/user-guide/install/download.html#hash-verification">Verify your installer hashes</a>.</p>
</li>
<li><p>In your terminal window, run:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure></li>
<li><p>Follow the prompts on the installer screens.</p>
<p>If you are unsure about any setting, accept the defaults. You can change them later.</p>
</li>
<li><p>To make the changes take effect, close and then re-open your terminal window.</p>
</li>
<li><p>Test your installation. In your terminal window or Anaconda Prompt, run the command <code>conda list</code>. A list of installed packages appears if it has been installed correctly.</p>
</li>
<li><p>默认的conda软件源是用来管理python模块的，必须添加bioconda的源才能下载到生物软件，以前推荐大家使用国内的镜像源，速度快很多。不过，前段时间所有国内镜像都不能用了，现在只能使用官方的源，不过速度还可以。在命令行运行以下两条命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda config --add channels bioconda</span><br><span class="line">conda config --add channels conda-forge</span><br></pre></td></tr></table></figure>

<p>然后将.condarc里面的– defaults删去。</p>
</li>
<li><p>如需更新miniconda：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda update conda</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="通过miniconda安装WES所需软件"><a href="#通过miniconda安装WES所需软件" class="headerlink" title="通过miniconda安装WES所需软件"></a>通过miniconda安装WES所需软件</h2><h3 id="软件列表"><a href="#软件列表" class="headerlink" title="软件列表"></a>软件列表</h3><table>
<thead>
<tr>
<th>包名</th>
<th align="left">用途</th>
<th>替代</th>
</tr>
</thead>
<tbody><tr>
<td>sra-tools</td>
<td align="left">下载sra；将sra转换为fastq</td>
<td>fasterq-dump</td>
</tr>
<tr>
<td>samtools</td>
<td align="left">用于操作sam和bam文件</td>
<td></td>
</tr>
<tr>
<td>bcftools</td>
<td align="left">calling/filtering/summarizing SNP and short INDEL sequence variants</td>
<td></td>
</tr>
<tr>
<td>vcftools</td>
<td align="left">对VCF文件和BCF文件进行格式转换及过滤</td>
<td></td>
</tr>
<tr>
<td>gatk4</td>
<td align="left">Genome Analysis ToolKit</td>
<td></td>
</tr>
<tr>
<td>snpeff</td>
<td align="left">通过基因组结构注释数据(GTF文件),对VCF文件中的SNP/InDel信息进行注释</td>
<td></td>
</tr>
<tr>
<td>multiqc</td>
<td align="left">数据质控</td>
<td></td>
</tr>
<tr>
<td>qualimap</td>
<td align="left">数据质控</td>
<td></td>
</tr>
<tr>
<td>gatk的bundle的hg38</td>
<td align="left">gatk分析流程所需的数据，包括参考基因组、注释及已经注释的SNP等</td>
<td></td>
</tr>
</tbody></table>
<p>安装前建议先使用conda search搜索以下有没有自己需要的版本，默认安装最新版。</p>
<h3 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda install -y sra-tools=2.11.0 samtools bcftools vcftools multiqc qualimap snpeff gatk4</span><br></pre></td></tr></table></figure>







]]></content>
      <categories>
        <category>WES</category>
      </categories>
  </entry>
  <entry>
    <title>测序数据下载及质控</title>
    <url>/2022/01/15/WES02/</url>
    <content><![CDATA[<h1 id="创建项目文件夹"><a href="#创建项目文件夹" class="headerlink" title="创建项目文件夹"></a>创建项目文件夹</h1><p>在主目录下新建一个”WES”文件夹：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir WES</span><br></pre></td></tr></table></figure>

<p>然后进入WES文件夹创建以下子文件夹：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd WES</span><br><span class="line">mkdir &#123;raw,clean,qc,align,mutation&#125;</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h1 id="数据下载"><a href="#数据下载" class="headerlink" title="数据下载"></a>数据下载</h1><h2 id="prefetch下载sra"><a href="#prefetch下载sra" class="headerlink" title="prefetch下载sra"></a>prefetch下载sra</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">prefetch --option-file raw/SraAccList.txt</span><br></pre></td></tr></table></figure>

<p>默认下载位置为~/ncbi，包括sra和转换所需的参考文件。</p>
<p>SraAccList.txt里为sra的Accession ID，用回车分割：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ERR3013393</span><br><span class="line">ERR3013392</span><br><span class="line">ERR3013391</span><br><span class="line">ERR3013389</span><br><span class="line">ERR3013388</span><br><span class="line">ERR3013387</span><br><span class="line">ERR3013386</span><br></pre></td></tr></table></figure>

<p>或者使用for循环：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for i in &#123;86,87,88,89,91,92,93&#125;</span><br><span class="line">do</span><br><span class="line">	prefetch ERR30133$i -O ~/WES/raw</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>sra文件大小相较fastq减少了将近80%。如果觉得麻烦，也可以直接到EMBL-EBI旗下的ENA数据库所搜该项目的project号<a href="https://www.ebi.ac.uk/ena/browser/view/PRJEB30330?show=reads">PRJEB30330</a>下载fastq的压缩文件。</p>
<h2 id="将sra转换为fastq"><a href="#将sra转换为fastq" class="headerlink" title="将sra转换为fastq"></a>将sra转换为fastq</h2><p>最新版sra-tools集成了fasterq-dump，相较fastq-dump，支持多线程，速度快10倍，但NCBI页面上只有fastq-dump的介绍而无fasterq-dump，可能是因为还不够方便稳定吧。</p>
<h3 id="安装最新sra-toolkit"><a href="#安装最新sra-toolkit" class="headerlink" title="安装最新sra toolkit"></a>安装最新sra toolkit</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">For ubuntu</span></span><br><span class="line">wget --output-document sratoolkit.tar.gz http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz #下载</span><br><span class="line">tar -vxzf sratoolkit.tar.gz #解压</span><br><span class="line">export PATH=$PATH:$PWD/sratoolkit.2.11.3-ubuntu64/bin #添加环境变量</span><br></pre></td></tr></table></figure>

<p>可以写一个shell脚本自动安装</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#！/bin/sh</span></span><br><span class="line">v=2.11.3 <span class="comment">#最新版版本号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># install perl and dependencies</span></span><br><span class="line">apt-get --quiet install --yes libxml-libxml-perl</span><br><span class="line"></span><br><span class="line"><span class="comment">#remove old install if any</span></span><br><span class="line">rm -rf .ncbi /usr/<span class="built_in">local</span>/ncbi /etc/ncbi /etc/profile.d/sra-tools*</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;installing sra toolkit to home/‘你的用户名’/sratoolkit.<span class="variable">$v</span>-unumtu64&quot;</span></span><br><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">wget --output-document sratoolkit.tar.gz http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz | tar -vxzf </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$PWD</span>/sratoolkit.<span class="variable">$v</span>-ubuntu64/bin</span><br></pre></td></tr></table></figure>

<h3 id="fasterq的用法"><a href="#fasterq的用法" class="headerlink" title="fasterq的用法"></a>fasterq的用法</h3><p>示例：fasterq-dump -p -e 8 -O ~/WES/raw ~/ncbi/public/sra/ERR3013386</p>
<p>不推荐：fasterq-dump -p -e 8 -O ~/WES/raw ~/ncbi/public/sra/ERR3013386/ERR3013386.sra</p>
<p><code>-p</code>为显示处理过程，<code>-e</code>指定线程数，<code>-O</code>指定输出文件夹。处理过程中会在ERR3013386文件夹中生成缓存文件，还会在当前目录生成tmp文件夹。fasterq-dump默认split 3参数，如果是双端测序则会输出1.fastq和2.fastq两个文件，单端则只输出*.fastq。详细用法见<a href="https://github-wiki-see.page/m/ncbi/sra-tools/wiki/HowTo%3A-fasterq-dump">usage</a>。</p>
<h3 id="使用fasterq-dump进行批处理"><a href="#使用fasterq-dump进行批处理" class="headerlink" title="使用fasterq-dump进行批处理"></a>使用fasterq-dump进行批处理</h3><p>法一、FOR循环</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for ((i=86;i&lt;=93;i++))</span><br><span class="line">	do </span><br><span class="line">	fasterq-dump -e 10 -p ~/ncbi/public/sra/ERR30133$i --outdir ~/WES/raw</span><br><span class="line">done #目前仍有bug，虽然数据下载到了本地，还是只能联网进行格式转换,可能因为序列不是SRR，软件不能识别</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>法二、xargs</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat ~/WES/raw/SraAccList.txt | xargs fasterq-dump -e 10 -p --outdir ~/WES/raw #但是这种只能在线下载sra序列进行转换</span><br></pre></td></tr></table></figure>

<h1 id="使用fastp进行质控"><a href="#使用fastp进行质控" class="headerlink" title="使用fastp进行质控"></a>使用fastp进行质控</h1><p>fastp集fastqc+cutadapt的功能于一体，可以一次性实现过滤低质量、修剪接头等操作，并输出质控报告，由深圳海普洛斯公司陈实富团队采用C++开发，运行效率较trimmomatic和cutadapt快2-5倍，软件开源。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">usage</span></span><br><span class="line">fastp -i R1.fq.gz -o R1.clean.fq.gz -I R2.fq.gz -O R2.fq.gz</span><br></pre></td></tr></table></figure>

<p>以上针对双端测序，单端测序只需输入/输出<code>-i/-o</code>即可，且无需压缩。其他参数：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-h, --html 设置输出html格式的质控结果文件名，不设置则默认html文件名为fastp.html</span><br><span class="line">-q, --qualified_quality_phred 设置碱基质量值不小于多少时，该碱基为合格碱基，默认碱基质量值是15，即默认碱基质量&gt;=15是合格碱基，&lt;15为不合格碱基</span><br><span class="line">-w 线程数，默认是3</span><br><span class="line">-f 指定单端头部碱基头部数量</span><br><span class="line">-t 指定单端尾部碱基去除数量</span><br><span class="line">-a 指定接头序列。fastp通过算法一般可以自动识别接头序列，尤其是PE数据，通过R1和R2的overlap可以准确识别</span><br></pre></td></tr></table></figure>

<p>但是multiqc目前不支持fastp，因此输出的质控报告只能一个一个查看，不能合并。</p>
<p>写个脚本进行批量质控</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for  i in ERR30133&#123;86,87,88,89,91,92,93&#125;</span><br><span class="line">do</span><br><span class="line">	fastp -i ~/WES/raw/$&#123;i&#125;.fastq.gz \</span><br><span class="line">		  -o ~/WES/clean/$&#123;i&#125;.clean.fastq.gz \</span><br><span class="line">		  -q 20 -w 10 -f 10 -t 30\</span><br><span class="line">		  -h ~/WES/clean/html/$&#123;i&#125;.html</span><br><span class="line">done</span><br></pre></td></tr></table></figure>





]]></content>
      <categories>
        <category>WES</category>
      </categories>
  </entry>
  <entry>
    <title>测序数据比对到参考基因组</title>
    <url>/2022/01/17/WES03/</url>
    <content><![CDATA[<p>Pipeline: Mapping→sorting→unique reads(mark duplicates)→indexing</p>
<span id="more"></span>

<h1 id="为什么需要将序列比对到参考基因组"><a href="#为什么需要将序列比对到参考基因组" class="headerlink" title="为什么需要将序列比对到参考基因组"></a>为什么需要将序列比对到参考基因组</h1><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>Burrows Wheeler Transformation</p>
<h1 id="常见比对工具"><a href="#常见比对工具" class="headerlink" title="常见比对工具"></a>常见比对工具</h1><p>bwa、bowtie2</p>
<h1 id="比对"><a href="#比对" class="headerlink" title="比对"></a>比对</h1><h2 id="建立参考基因组索引"><a href="#建立参考基因组索引" class="headerlink" title="建立参考基因组索引"></a>建立参考基因组索引</h2><p>绝大多数比对工具都需要先对参考基因组建立索引。我们可以使用下面的命令对参考基因组创建索引文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bwa index &lt;reference.fasta&gt;</span><br></pre></td></tr></table></figure>

<p>因此让我们使用这个命令对我们需要的人类参考基因组hg38建立索引：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bwa index ~/WES/ref/hg38.fna</span><br></pre></td></tr></table></figure>

<p>执行成功后，会在参考基因组所在目录生成5个新文件，它们的basename都来自hg38。这些索引文件都是BWA比对需要的。</p>
<p><img src="/2022/01/17/WES03/01.png"></p>
<p>注意：如果参考基因组大于2GB，那么使用BWA建立索引时需要加参数<code>-a bwtsw</code>,这个算法速度慢，但节省内存。</p>
<h2 id="比对-1"><a href="#比对-1" class="headerlink" title="比对"></a>比对</h2><p>建立索引后，我们就可以将测序数据比对到参考基因组上了。用法如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bwa mem -M -R &lt;ref&gt; &lt;R1.fastq&gt; &lt;R2.fastq&gt; </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">参数解释：</span><br><span class="line">mem是bwa比对使用的三种算法之一，支持长序列（70bp~1Mbp）比对,官方推荐的最新算法。</span><br><span class="line">-M 将shorter split hits标记为次优，以兼容Picard’s markDuplicates软件</span><br><span class="line">-R 指定每个read前加上@RG\tID:foo\tSM:bar之类的标头，使用\t分隔。</span><br><span class="line">-t 线程数，默认1</span><br><span class="line">&lt;ref&gt; 参考基因组文件。同时，所有的索引文件都要在同一个文件夹。</span><br><span class="line">&lt;R1.fastq&gt;,&lt;R2.fastq&gt; 单端只输入一个即可。bwa不支持压缩文件，使用记得前先解压。</span><br></pre></td></tr></table></figure>

<p>因此运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bwa mem -t 8 -M -R &#x27;@RG\tID:sample\tLB:sample\tPL:Ion\tSM:sample&#x27; ~/WES/ref/hg38.fna ~/WES/clean/ERR3013386.clean.fastq \</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> ~/WES/align/ERR3013386.sam <span class="comment">#使用&gt;将比对结果重定向到.sam文件保存</span></span> </span><br></pre></td></tr></table></figure>

<p>批处理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for i in ERR30133&#123;86,87,88,89,91,92,93&#125;</span><br><span class="line">	do</span><br><span class="line">	bwa mem -t 8 -M -R &#x27;@RG\tID:$i\tLB:$i\tPL:Ion\tSM:$i&#x27; \</span><br><span class="line">    ~/WES/ref/hg38.fna \</span><br><span class="line">    ~/WES/clean/$i.clean.fastq \</span><br><span class="line">    &gt; ~/WES/align/$i.sam</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h2 id="输出比对信息"><a href="#输出比对信息" class="headerlink" title="输出比对信息"></a>输出比对信息</h2><p>使用samtools flagstat工具对比对结果进行统计：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools flagstat [options] &lt;in.bam&gt;</span><br></pre></td></tr></table></figure>

<p>以单端测序数据ERR3013386的sam比对文件为例：</p>
<p><img src="/2022/01/17/WES03/02.png"></p>
<p>比对结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2166159 + 0 in total (QC-passed reads + QC-failed reads)  #reads总数</span><br><span class="line">5038 + 0 secondary  #比对到参考基因组多个位置的reads数</span><br><span class="line">0 + 0 supplementary  #可能存在嵌合的reads数</span><br><span class="line">0 + 0 duplicates  #重复的reads数</span><br><span class="line">2153012 + 0 mapped (99.39% : N/A)  #比对到参考基因组的reads数</span><br><span class="line">0 + 0 paired in sequencing  #属于PE的reads数</span><br><span class="line">0 + 0 read1  #PE中Read_1的reads数</span><br><span class="line">0 + 0 read2  #PE中Read_2的reads数</span><br><span class="line">0 + 0 properly paired (N/A : N/A)  #完美比对的reads数：PE两端reads比对到同一条序列，且根据比对结果推断的插入片段大小符合设置的阈值</span><br><span class="line">0 + 0 with itself and mate mapped  #PE两端都比对上参考序列的reads数</span><br><span class="line">0 + 0 singletons (N/A : N/A)  #PE两端，一端比对上而另一端没比对上的reads数</span><br><span class="line">0 + 0 with mate mapped to a different chr  #PE两端分别比对到不同染色体上的reads数</span><br><span class="line">0 + 0 with mate mapped to a different chr (mapQ&gt;=5)  #PE中两端分别比对到两条不同染色体，且mapQ&gt;=5的reads数</span><br></pre></td></tr></table></figure>

<p>批处理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">touch ~/WES/align/flagstat.txt #建立一个空txt保存比对结果</span><br><span class="line">for i in ERR30133&#123;86,87,88,89,91,92,93&#125;</span><br><span class="line">	do</span><br><span class="line">	echo $i &gt;&gt; flagstat.txt #追加标头</span><br><span class="line">	samtools flagstat ~/WES/align/$i* &gt;&gt; flagstat.txt #追加比对结果</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>运行完cat一下：</p>
<p><img src="/2022/01/17/WES03/03.png"></p>
<h2 id="sam文件排序并转换为bam"><a href="#sam文件排序并转换为bam" class="headerlink" title="sam文件排序并转换为bam"></a>sam文件排序并转换为bam</h2><p>比对数据的下游分析要求按坐标顺序排好序的bam格式。因此，我们使用samtools工具来操作：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools sort ~/WES/align/ERR3013386.sam -O BAM -o ~/WES/align/ERR3013386.sorted.bam</span><br></pre></td></tr></table></figure>

<p>看一下转换前后有什么不同：</p>
<p><img src="/2022/01/17/WES03/04.png" alt="aligned.sam"></p>
<p><img src="/2022/01/17/WES03/05.png" alt="aligned.sorted.bam"></p>
<p>简单来说就是按照第四列的坐标由小到大重新进行了排列。关于SAM格式文件说明可以详见这篇<a href="https://www.jianshu.com/p/ab133ee9712c">文章</a>。</p>
<p>批处理：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for i in ERR30133&#123;86,87,88,89,91,92,93&#125;</span><br><span class="line">  do</span><br><span class="line">  samtools sort ~/WES/align/$i.sam -O BAM -o ~/WES/align/$i.sorted.bam</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<ul>
<li>比对＋sort</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#使用管道避免产生中间的SAM比对文件</span><br><span class="line">for i in ERR30133&#123;86,87,88,89,91,92,93&#125;</span><br><span class="line">	do</span><br><span class="line">	bwa mem -t 8 -M -R &#x27;@RG\tID:$i\tLB:$i\tPL:Ion\tSM:$i&#x27; \</span><br><span class="line">    ~/WES/ref/hg38.fna \</span><br><span class="line">    ~/WES/clean/$i.clean.fastq \</span><br><span class="line">    | samtools sort -O BAM -o ~/WES/align/$i.sorted.bam</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h2 id="标记重复"><a href="#标记重复" class="headerlink" title="标记重复"></a>标记重复</h2><p>测序过程中，同一条DNA片段可能会被多次测序。这些重复的reads不是有效信息，也不能作为支持或反对潜在变异的证据。最常见的引起duplicates的原因就是文库构建过程中的PCR。如果不去除这些<strong>PCR duplicates</strong>，PCR扩增偏好性的区域就存在过表达的风险。生成测序cluster时，如果某一个cluster中的DNA序列搭到附近另一个cluster的生成位点，就会又生成一个相同的cluster，产生<strong>Cluster duplicates</strong>。cluster在测序时，捕获的荧光亮点由于光波的衍射，导致形状出现重影，而被当做两个荧光点来处理，从而被认作两条相同的reads，这类称为<strong>Optical duplicates</strong>。</p>
<p>因此我们需要将这些duplicates标记出来，从而得到未被标记的unique reads。最常见的Mark Duplicates工具主要有samtools、picard和sambamba。其中，samtools步骤较繁琐，picard使用最广泛，sambamba处理速度快且用法简单。因此这里推荐使用sambamba。实际上，sambamba开发之初就是为了替代samtools，详细功能参见这篇<a href="https://github.com/biod/sambamba/wiki/Command-line-tools">文档</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#用法</span><br><span class="line">sambamba markdup OPTIONS &lt;input.bam&gt; &lt;output.bam&gt;</span><br></pre></td></tr></table></figure>

<p>批处理</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#这一步会同时建立索引</span><br><span class="line">for i in ERR30133&#123;86,87,88,89,91,92,93&#125;</span><br><span class="line">  do</span><br><span class="line">  sambamba markdup ~/WES/align/$i.sorted.bam $i.sorted.markdup.bam</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h1 id="GATK-resource-bundle"><a href="#GATK-resource-bundle" class="headerlink" title="GATK resource bundle"></a>GATK resource bundle</h1><p>下载GATK提供的resource bundle，里面提供了下游分析需要的数据。目前提供FTP 和 Google Cloud bucket 2种下载方式，由于用不了Google，只能使用FTP。GATK官网推荐使用lftp工具进行访问ftp和下载数据。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#远程访问ftp服务器</span><br><span class="line">lftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/</span><br><span class="line">没有密码，因此直接敲回车即可。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ls	#查看以下当前目录下的内容</span><br></pre></td></tr></table></figure>

<p><img src="/2022/01/17/WES03/06.png"></p>
<p>这里我们只需将hg38文件夹里的所有内容下载到本地即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mirror hg38</span><br></pre></td></tr></table></figure>

<p>常见ftp服务器的命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">get [OPTS] &lt;rfile&gt; [-o &lt;lfile&gt;] #下载文件</span><br><span class="line">mget [OPTS] &lt;files&gt;  #支持使用通配符来下载文件</span><br><span class="line">mirror [OPTS] [remote [local]]  #下载整个文件夹</span><br><span class="line"></span><br><span class="line">help  #查看所有命令</span><br><span class="line">help &lt;cmd&gt;  #查看某条命令的help</span><br></pre></td></tr></table></figure>

<h1 id="Prepare-reference-dictionary-fasta-index-and-bam-index"><a href="#Prepare-reference-dictionary-fasta-index-and-bam-index" class="headerlink" title="Prepare reference dictionary, fasta index, and bam index"></a>Prepare reference dictionary, fasta index, and bam index</h1><p>使用GATK整合的picard工具建立参考基因组字典文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gatk --java-options &quot;-Xmx8G&quot; CreateSequenceDictionary \</span><br><span class="line">     -R ~/WES/ref/hg38.fna \</span><br><span class="line">     -O ~/WES/ref/hg38.dict</span><br></pre></td></tr></table></figure>

<p>使用samtools建立参考基因组索引：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools faidx ~/WES/ref/hg38.fna  #在参考基因组同位置生成一个.fai索引文件</span><br></pre></td></tr></table></figure>

<p>使用samtools建立markdup.bam文件的索引：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools index markdup.bam  #上面已经生成，这里就简单提一下</span><br></pre></td></tr></table></figure>

<p>这三类索引文件都是GATK下游分析所需要的。其中，前两个文件resource bundle里也有。</p>
]]></content>
      <categories>
        <category>WES</category>
      </categories>
  </entry>
  <entry>
    <title>碱基质量重矫正</title>
    <url>/2022/01/20/WES04/</url>
    <content><![CDATA[<p>GATK是目前业内最权威、使用最广泛的变异检测工具。目前最新版为GATK4，相比GATK3，GATK4在一些工具的使用及参数的设置上都有所优化，取消了Indel的Realignment。</p>
<span id="more"></span>

<p>之所以需要进行Indel局部区域重比对，一是因为BWA和bowtie等全局搜索最优匹配的算法在Indel区域及附近的比对情况往往不是很理想。二是这些算法对于碱基错配和gap的容忍度不同，如果发现碱基错配和gap都可以的情况，会更偏向于错配，这就可能导致基因组上原本应该是一个长Indel的区域被错误地比对为多个错配和短Indel，必然导致检测到错误的变异。</p>
<p>Indel的Realignment就是将BWA比对过程中发现的有潜在Indel的区域进行局部比对，从而重新矫正，降低识别到错误变异的几率。</p>
<p>GATK表示如果使用了最新的HaplotypeCaller或者MuTect2，就不需要这一步了，很可能是GATK4的新工具HaplotypeCaller具备了这一功能。如果使用传统的caller工具，如UnifiedGenotyper或者MuTect，则这一步还是需要的。</p>
<h1 id="碱基质量重矫正"><a href="#碱基质量重矫正" class="headerlink" title="碱基质量重矫正"></a>碱基质量重矫正</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>BQSR就是Base Quality Score Recalibration，即碱基质量重矫正。这也是数据预处理的最后一步，主要是为了纠正测序仪在测序过程中产生的系统性错误。这类错误有些是因为测序反应中物理或化学反应导致的，有些可能是设备操作上出错了。</p>
<h2 id="BQSR过程详解"><a href="#BQSR过程详解" class="headerlink" title="BQSR过程详解"></a>BQSR过程详解</h2><h3 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h3><p>1.首先提供GATK Base Recalibrator一些列已知的变异集。</p>
<p>2.GATK Base Recalibrator会分析所有的reads，寻找read和reference存在错配的位置，然后排除已知的变异位置。</p>
<p>3.GATK Base Recalibrator根据错配序列碱基原有的质量值、位置和序列内容计算错配碱基的相关数据。</p>
<p>4.基于第3步计算的数据和经验，通过机器学习给每个错配碱基重新计算出新的质量值，代替原来的。</p>
<h3 id="第一步：BaseRecalibrator建模"><a href="#第一步：BaseRecalibrator建模" class="headerlink" title="第一步：BaseRecalibrator建模"></a>第一步：BaseRecalibrator建模</h3><p>为了建立协变量模型，这个工具会遍历输入的BAM文件中所有的reads，然后按列输出碱基的以下特征：</p>
<ul>
<li>read的read group。Read group即前面比对过程中添加以@RG开头的标头，需要通过Read group标签来对reads进行分组矫正。其中：</li>
</ul>
<blockquote>
<p><code>ID</code>=Read group ID，每个read group都有独自的ID。Illumina测序数据中，ID由flowcell、lane name和number组成。矫正碱基质量时，ID对区分技术批次效应是必须的。在这个过程，同一ID的read被假定为有同样的技术误差。</p>
</blockquote>
<blockquote>
<p><code>PU</code>=Platform unit。由三部分组成，<flowcell_barcode>.&lt;lane&gt;.<sample_barcode>。PU不是必须要求的，但是PU的优先级高于ID。</sample_barcode></flowcell_barcode></p>
</blockquote>
<blockquote>
<p><code>SM</code>=Sample。reads所属的样品名。SM要设定正确，因为GATK产生的VCF文件也使用这个名字。</p>
</blockquote>
<blockquote>
<p><code>PL</code>=platform。主要有ILLUMINA、SOLID、LS454、HELICOS和PACBIO等。</p>
</blockquote>
<blockquote>
<p><code>LB</code>=DNA preparation library identifier。对一个read group的reads进行重复序列标记时，需要使用LB来区分reads来自哪条lane。有时同一个库可能在不同的lane上完成的测序，为了加以区分，只要是来自不同的lane都要单独赋予一个ID。</p>
</blockquote>
<ul>
<li>测序仪给出的碱基质量值</li>
<li>碱基产生的轮次（Nth cycle = Nth base from the start of the read）</li>
<li>连续两个碱基（dinucleotide）</li>
</ul>
<p>For each bin, we count the number of bases within the bin and how often such bases mismatch the reference base, excluding loci known to vary in the population, according to the known variants resource (typically dbSNP). This information is output to a recalibration file in GATKReport format.</p>
<p>Note that the recalibrator applies a “yates” correction for low occupancy bins. Rather than inferring the true Q score from # mismatches / # bases we actually infer it from (# mismatches + 1) / (# bases + 2). This deals very nicely with overfitting problems, which has only a minor impact on data sets with billions of bases but is critical to avoid overconfidence in rare bins in sparse data.</p>
<p>这个目前还不是很理解，暂时搬到这里，以后有更深的理解后再更新吧。</p>
<h3 id="第二步：ApplyBQSR-adjusts-the-scores"><a href="#第二步：ApplyBQSR-adjusts-the-scores" class="headerlink" title="第二步：ApplyBQSR adjusts the scores"></a>第二步：ApplyBQSR adjusts the scores</h3><p>This second tool goes through all the reads again, using the recalibration file to adjust each base’s score based on which bins it falls in. So effectively the new quality score is:</p>
<ul>
<li>the sum of the global difference between reported quality scores and the empirical quality</li>
<li>plus the quality bin specific shift</li>
<li>plus the cycle x qual and dinucleotide x qual effect</li>
</ul>
<p>Following recalibration, the read quality scores are much closer to their empirical scores than before. This means they can be used in a statistically robust manner for downstream processing, such as variant calling. In addition, by accounting for quality changes by cycle and sequence context, we can identify truly high quality bases in the reads, often finding a subset of bases that are Q30 even when no bases were originally labeled as such.</p>
<h2 id="BQSR具体操作"><a href="#BQSR具体操作" class="headerlink" title="BQSR具体操作"></a>BQSR具体操作</h2><h3 id="第一步：协变量分析"><a href="#第一步：协变量分析" class="headerlink" title="第一步：协变量分析"></a>第一步：协变量分析</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gatk BaseRecalibrator \</span><br><span class="line">-R ~/WES/ref/hg38.fna \</span><br><span class="line">-I ~/WES/align/ERR3013386.sorted.markdup.bam \</span><br><span class="line">-known-sites ~/WES/gatk_resource_bundle/hg38/dbsnp_146.hg38.ncbi.vcf \</span><br><span class="line">-known-sites ~/WES/gatk_resource_bundle/hg38/Mills_and_1000G_gold_standard.indels.hg38.ncbi.vcf \</span><br><span class="line">-known-sites ~/WES/gatk_resource_bundle/hg38/1000G_phase1.snps.high_confidence.hg38.ncbi.vcf \</span><br><span class="line">-O ~/WES/align/ERR3013386.recal_data.table</span><br></pre></td></tr></table></figure>





<h3 id="第二步：调整质量值"><a href="#第二步：调整质量值" class="headerlink" title="第二步：调整质量值"></a>第二步：调整质量值</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gatk ApplyBQSR \</span><br><span class="line">		 -I ~/WES/align/ERR3013386.sorted.markdup.bam \</span><br><span class="line">		 -bqsr ~/WES/align/ERR3013386.recal_data.table \</span><br><span class="line">		 -O ~/WES/align/ERR3013386.markdup.recal.bam</span><br></pre></td></tr></table></figure>

<h3 id="批处理"><a href="#批处理" class="headerlink" title="批处理"></a>批处理</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">for i in ERR30133&#123;86,87,88,89,91,92,93&#125;</span><br><span class="line">	do</span><br><span class="line">	gatk BaseRecalibrator \</span><br><span class="line">		-R ~/WES/ref/hg38.fna \</span><br><span class="line">		-I ~/WES/align/$i.sorted.markdup.bam \</span><br><span class="line">		-known-sites ~/WES/gatk_resource_bundle/hg38/dbsnp_146.hg38.ncbi.vcf \</span><br><span class="line">		-known-sites ~/WES/gatk_resource_bundle/hg38/Mills_and_1000G_gold_standard.indels.hg38.ncbi.vcf \</span><br><span class="line">		-known-sites ~/WES/gatk_resource_bundle/hg38/1000G_phase1.snps.high_confidence.hg38.ncbi.vcf \</span><br><span class="line">		-O ~/WES/align/$i.recal_data.table </span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">for i in ERR30133&#123;86,87,88,89,91,92,93&#125;</span><br><span class="line">	do</span><br><span class="line">	gatk ApplyBQSR \</span><br><span class="line">		-I ~/WES/align/$i.sorted.markdup.bam \</span><br><span class="line">		-bqsr ~/WES/align/$i.recal_data.table \</span><br><span class="line">		-O ~/WES/align/$i.markdup.recal.bam </span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p> 关于BQSR要不要使用-L参数来限定仅对外显子区域操作，官方回答是不建议。</p>
<h3 id="WHAT-IF"><a href="#WHAT-IF" class="headerlink" title="WHAT IF"></a>WHAT IF</h3><h4 id="（一）"><a href="#（一）" class="headerlink" title="（一）"></a>（一）</h4><p>如果提示：<code>A USER ERROR has occurred: Input files reference and features have incompatible contigs: No overlapping contigs found.</code>可能是因为从GATK的resource bundle里下载的VCF文件里染色体的命名方式与参考基因组不一致。</p>
<p>NCBI参考基因组文件的标头：<code>NC_000001.11 Homo sapiens chromosome 1, GRCh38.p13 Primary Assembly</code></p>
<p>GRCh38.p13参考基因组NC编号与对应染色体</p>
<table>
<thead>
<tr>
<th align="center">NC_000001.11</th>
<th align="center">NC_000002.12</th>
<th align="center">NC_000003.12</th>
<th align="center">NC_000004.12</th>
<th align="center">NC_000005.10</th>
</tr>
</thead>
<tbody><tr>
<td align="center">chr1</td>
<td align="center">chr2</td>
<td align="center">chr3</td>
<td align="center">chr4</td>
<td align="center">chr5</td>
</tr>
<tr>
<td align="center"><strong>NC_000006.12</strong></td>
<td align="center"><strong>NC_000007.14</strong></td>
<td align="center"><strong>NC_000008.11</strong></td>
<td align="center"><strong>NC_000009.12</strong></td>
<td align="center"><strong>NC_000010.11</strong></td>
</tr>
<tr>
<td align="center">chr6</td>
<td align="center">chr7</td>
<td align="center">chr8</td>
<td align="center">chr9</td>
<td align="center">chr10</td>
</tr>
<tr>
<td align="center"><strong>NC_000011.10</strong></td>
<td align="center"><strong>NC_000012.12</strong></td>
<td align="center"><strong>NC_000013.11</strong></td>
<td align="center"><strong>NC_000014.9</strong></td>
<td align="center"><strong>NC_000015.10</strong></td>
</tr>
<tr>
<td align="center">chr11</td>
<td align="center">chr12</td>
<td align="center">chr13</td>
<td align="center">chr14</td>
<td align="center">chr15</td>
</tr>
<tr>
<td align="center"><strong>NC_000016.10</strong></td>
<td align="center"><strong>NC_000017.11</strong></td>
<td align="center"><strong>NC_000018.10</strong></td>
<td align="center"><strong>NC_000019.10</strong></td>
<td align="center"><strong>NC_000020.11</strong></td>
</tr>
<tr>
<td align="center">chr16</td>
<td align="center">chr17</td>
<td align="center">chr18</td>
<td align="center">chr19</td>
<td align="center">chr20</td>
</tr>
<tr>
<td align="center"><strong>NC_000021.9</strong></td>
<td align="center"><strong>NC_000022.11</strong></td>
<td align="center"><strong>NC_000023.11</strong></td>
<td align="center"><strong>NC_000024.10</strong></td>
<td align="center"><strong>NC_012920.1</strong></td>
</tr>
<tr>
<td align="center">chr21</td>
<td align="center">chr22</td>
<td align="center">chrX</td>
<td align="center">chrY</td>
<td align="center">mitochondrion</td>
</tr>
</tbody></table>
<p>PS:NC编号中小数点后的数字表示版本。</p>
<p>dbsnp.vcf里的染色体命名格式是UCSC风格：<code>chr1    10019   rs775809821     TA      T       .       .       RS=775809821;RSPOS=10020;dbSNPBuildID=144;SSR=0;SAO=0;VP=0x050000020005000002000200;GENEINFO=DDX11L1:100287102;WGT=1;VC=DIV;R5;ASP</code></p>
<p>因此在进行比对时匹配不上。所以解决办法要么改变基因组，要么改变VCF。而改变又有两种方式，要么手动修改，要么下载匹配的格式。</p>
<p>这里选择最头铁的方式，将vcf里UCSC style的染色体名改为NCBI的编号形式。感谢这位兄弟提供的小工具<a href="https://github.com/vkkodali/cthreepo">cthreepo</a>，支持GFF、GTF、BED、VCF、SAM等文件的染色体ID在NCBI、UCSC和Ensembl之间转换。</p>
<p>安装cthreepo：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">clone</span> the repository</span></span><br><span class="line">git clone https://github.com/vkkodali/cthreepo.git</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">run the following to install</span></span><br><span class="line">python3 setup.py install</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">execute as follows</span></span><br><span class="line"><span class="meta">#</span><span class="bash">convert seq-ids <span class="keyword">in</span> &lt;input.gff3&gt; from refseq format (NC_000001.11) to UCSC format (chr1) using the Human GRCh38 mapping dictionary</span></span><br><span class="line">cthreepo \</span><br><span class="line">    --infile &lt;input.gff3&gt; \</span><br><span class="line">    --id_from rs \</span><br><span class="line">    --id_to uc \</span><br><span class="line">    --format gff3 \</span><br><span class="line">    --mapfile h38 \</span><br><span class="line">    --outfile &lt;output.gff3&gt;</span><br><span class="line">    </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">help</span></span></span><br><span class="line">cthreepo --help</span><br></pre></td></tr></table></figure>

<p>然后下载NCBI提供的<a href="https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_assembly_report.txt">assembly report</a>文件到本地或者添加-a参数指定NCBI Assembly Accession with version来在线获取，cthreepo就是根据这个文件的ID注释进行转换的。</p>
<p>将3个vcf文件转换为我们所需要的：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">Mills_and_1000G</span></span><br><span class="line">cthreepo \</span><br><span class="line">--infile ~/WES/gatk_resource_bundle/hg38/Mills_and_1000G_gold_standard.indels.hg38.vcf \</span><br><span class="line">--id_from uc --id_to rs --format vcf \</span><br><span class="line">-a GCF_000001405.39 \</span><br><span class="line">--outfile ~/WES/gatk_resource_bundle/hg38/Mills_and_1000G_gold_standard.indels.hg38.ncbi.vcf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">1000G</span></span><br><span class="line">cthreepo \</span><br><span class="line">--infile ~/WES/gatk_resource_bundle/hg38/1000G_phase1.snps.high_confidence.hg38.vcf \</span><br><span class="line">--id_from uc --id_to rs --format vcf \</span><br><span class="line">-a GCF_000001405.39 \</span><br><span class="line">--outfile ~/WES/gatk_resource_bundle/hg38/1000G_phase1.snps.high_confidence.hg38.ncbi.vcf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">dbsnp_146</span></span><br><span class="line">cthreepo \</span><br><span class="line">--infile ~/WES/gatk_resource_bundle/hg38/dbsnp_146.hg38.vcf \</span><br><span class="line">--id_from uc --id_to rs --format vcf \</span><br><span class="line">-a GCF_000001405.39 \</span><br><span class="line">--outfile ~/WES/gatk_resource_bundle/hg38/dbsnp_146.hg38.ncbi.vcf</span><br></pre></td></tr></table></figure>

<p>看看转换前后对比：</p>
<p><img src="/2022/01/20/WES04/01.png" alt="before"></p>
<p><img src="/2022/01/20/WES04/02.png" alt="after"></p>
<p>但是再次运行gatk BaseRecalibrator后发现还是提示reference和features的contigs还是不匹配。单独指定vcf后运行发现，仅dbsnp_146运行成功。通过比较与另外两个VCF的差别后发现，dbsnp_146没有<code>##contig=&lt; &gt;</code>这部分codecs：</p>
<p><img src="/2022/01/20/WES04/03.png"></p>
<p>因此猜想是这部分编码内容误导了gatk，于是将这两个VCF里的删去，并重建索引：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">以下代码在文件所在目录运行</span></span><br><span class="line">mv Mills_and_1000G_gold_standard.indels.hg38.ncbi.vcf Mills_and_1000G_gold_standard.indels.hg38.ncbi.old.vcf</span><br><span class="line">grep -v &quot;##contig=&quot; Mills_and_1000G_gold_standard.indels.hg38.ncbi.old.vcf &gt; Mills_and_1000G_gold_standard.indels.hg38.ncbi.vcf </span><br><span class="line">gatk IndexFeatureFile -I Mills_and_1000G_gold_standard.indels.hg38.ncbi.vcf</span><br><span class="line">rm -rf Mills_and_1000G_gold_standard.indels.hg38.ncbi.old.vcf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">另一个同理</span></span><br><span class="line">mv 1000G_phase1.snps.high_confidence.hg38.ncbi.vcf 1000G_phase1.snps.high_confidence.hg38.ncbi.old.vcf</span><br><span class="line">grep -v &quot;##contig=&quot; 1000G_phase1.snps.high_confidence.hg38.ncbi.old.vcf &gt; 1000G_phase1.snps.high_confidence.hg38.ncbi.vcf </span><br><span class="line">gatk IndexFeatureFile -I 1000G_phase1.snps.high_confidence.hg38.ncbi.vcf</span><br><span class="line">rm -rf 1000G_phase1.snps.high_confidence.hg38.ncbi.old.vcf</span><br></pre></td></tr></table></figure>

<p>再次运行，提示<code>success</code>。</p>
<h4 id="（二）"><a href="#（二）" class="headerlink" title="（二）"></a>（二）</h4><p>如果提示：<code>A USER ERROR has occurred: Input /home/yico/WES/gatk_resource_bundle/hg38/dbsnp_146.hg38.ncbi.vcf must support random access to enable queries by interval. If it&#39;s a file, please index it using the bundled tool IndexFeatureFile</code>或下载了原始的tbi索引，则需使用IndexFeatureFile对VCF文件重新建立索引。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">usage</span></span><br><span class="line">gatk IndexFeatureFile -I &lt;input.vcf&gt;  </span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>WES</category>
      </categories>
  </entry>
  <entry>
    <title>Variants Calling</title>
    <url>/2022/01/24/WES05/</url>
    <content><![CDATA[<p>经过前面的预处理工作得到处理好的bam文件，我们就可以开始下游的找变异分析了。</p>
<p>主要分析包括三步：</p>
<ul>
<li><strong>Call variants</strong></li>
<li>Filter variants</li>
<li>Annotation</li>
</ul>
<p>今天我们先学习Call variants。</p>
<span id="more"></span>

<h1 id="变异检出"><a href="#变异检出" class="headerlink" title="变异检出"></a>变异检出</h1><p>Variant calling使用的是gatk的HaplotypeCaller工具，简称HC。它能够通过对活跃区域（与参考基因组不同处较多的区域）局部单倍型重组装，找出SNP和Indel。这一步最大化了对变异的敏感度，从而减少假阴性的结果。</p>
<p>HaplotypeCaller的核心操作就是四步：</p>
<ol>
<li><p>寻找活跃区域（与参考基因组不同部分较多的区域）</p>
</li>
<li><p>通过对该区域进行局部重组装，确定单倍型（haplotypes）。就是这一步可以省去indel realignment</p>
</li>
<li><p>在给定的read数据下，计算单倍型的可能性。</p>
</li>
<li><p>分配样本的基因型</p>
</li>
</ol>
<p>HaplotypeCaller有两种模式，一种是直接生成VCF，适合于单样本。另一种是ERC模式，会先生成gVCF，然后再将多个样本的gVCF合在一个gVCF进行joint-call，根据这个gVCF检出变异，适合多个样本，多个样本同时分析可以增加某个变异位点的可信度。所以一般推荐使用第二种模式。</p>
<p>第一种模式</p>
<p>使用起来比较简单。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">usage</span></span><br><span class="line">gatk HaplotypeCaller -R &lt;reference&gt; -L exon.bed -I &lt;in.bam&gt; -O &lt;raw.vcf&gt;</span><br></pre></td></tr></table></figure>

<p>第二种模式</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">首先生成中间的gVCF文件</span></span><br><span class="line">for i in ERR30133&#123;86,87,88,89,91,92,93&#125;</span><br><span class="line">do</span><br><span class="line">gatk --java-options &quot;-Xmx8G&quot; HaplotypeCaller \</span><br><span class="line">	-R ~/WES/ref/hg38.fna \</span><br><span class="line">	--emit-ref-confidence GVCF \</span><br><span class="line">	-I ~/WES/align/$i.markdup.recal.bam \</span><br><span class="line">	-O ~/WES/align/$i.gvcf</span><br><span class="line">done</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">然后将多个样本的gVCF文件合并在一起</span></span><br><span class="line">gatk CombineGVCFs -R ~/WES/ref/hg38.fna --arguments_file ~/WES/align/gvcf_input.list -O ~/WES/align/final.gvcf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">根据gVCF检出变异</span></span><br><span class="line">gatk --java-options &quot;-Xmx8G -Djava.io.tmpdir=/home/yico/tmp&quot; GenotypeGVCFs \</span><br><span class="line">	-R ~/WES/ref/hg38.fna 	\</span><br><span class="line">	-V ~/WES/align/final.gvcf \</span><br><span class="line">	-O ~/WES/mutation/raw.vcf</span><br></pre></td></tr></table></figure>

<p>虽然是外显子，但不指定-L参数的exon.bed反而可以运行得很顺利，目前不清楚这样对结果有什么影响。</p>
]]></content>
      <categories>
        <category>WES</category>
      </categories>
  </entry>
  <entry>
    <title>Variants Filtering</title>
    <url>/2022/01/25/WES06/</url>
    <content><![CDATA[<p>今天来学习DNA-seq下游分析的第二个内容<code>Filter variants</code>。</p>
<ul>
<li>Call variants</li>
<li><strong>Filter variants</strong></li>
<li>Annotation</li>
</ul>
<p>本篇内容包括了变异质控<code>VQSR</code>建模和<code>hard-filters</code>硬过滤两种不同的方法及原理的介绍。</p>
<span id="more"></span>

<h1 id="VQSR"><a href="#VQSR" class="headerlink" title="VQSR"></a>VQSR</h1><p>得到变异数据后，通常需要对其进行过滤质控，筛去假阳性。通常会使用gatk VQSR工具来过滤。</p>
<h2 id="人类变异数据集"><a href="#人类变异数据集" class="headerlink" title="人类变异数据集"></a>人类变异数据集</h2><p>VQSR需要已知的高质量变异数据集作为训练数据进行建模。对于人类而言常见的数据集按质量排序包括SNP: HapMap &gt; Omni &gt; 1000G &gt; dbSNP; Indel: Mills &gt; dbSNP。</p>
<h3 id="训练集参数说明"><a href="#训练集参数说明" class="headerlink" title="训练集参数说明"></a>训练集参数说明</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--resource:hapmap,known=false,training=true,truth=true,prior=15.0 hapmap_3.3.hg38.sites.vcf.gz</span><br></pre></td></tr></table></figure>

<p>这个<code>--resource</code>指定VQSR用于建模的变异数据集，从左往右用<code>,</code>隔开，依次为：</p>
<ul>
<li>训练集名字，这个名字是可以随便改动的，但是为了便于交流，一般按照数据集的名字来设置。</li>
<li>known：该数据是否作为已知变异数据集，用于对变异数据的标注。</li>
<li>training：该数据是否作为模型训练的数据集，用于训练VQSR模型。</li>
<li>truth：该数据是否作为验证模型训练的真集数据，这个数据同时还是VQSR训练bad model时自动进行参数选择的重要数据。</li>
<li>prior：该数据集在VQSR模型训练中的权重（这里使用Phred值，如20表示0.99）。</li>
</ul>
<h3 id="SNP变异数据集"><a href="#SNP变异数据集" class="headerlink" title="SNP变异数据集"></a>SNP变异数据集</h3><p>HapMap，它来自国际人类单倍体型图计划，HapMap的名字也是源自于此。这个项目刚启动之时，只有270样本，其中有60个家系。项目一共有三期，到第三期HapMap3的时候这个数据已经扩增到1301个样本了，其中有部分样本和千人基因组项目有重叠。由于这个数据集包含了大量家系数据，并且有非常严格的质控和严密的实验验证，因此它的准确性是目前公认最高的。所以VQSR进行质控模型训练的时候，会将其作为一个很重要的训练集（training=true）。它的权重也会被设置得很高，比如在WES数据分析中常常设为prior=15——这里的Prior是Prior likelihood的Phred-scale，我们如果把15转换为likelihood，那么就是0.96838。此外，由于它的高准确性，通常还将作为模型验证的一个真集数据（truth=true）。</p>
<p>Omni，这个数据源自Illumina的Omni基因型芯片，大概2.5百万个位点（我在知识星球中说是1M，这里纠正一下，应该是2.5M），它的验证结果常常作为基因型的金标准。比如用Omni芯片对千人基因组数据进行了验证的结果：1000G_omni2.5.hg38.vcf（这里hg38是参考序列版本），它也是一个高可信的变异结果，我们在VQSR模型训练的时候，同样可以为其设置很高的权重，一般为Prior=12(likelihood为0.9369)。通常情况下也可以把它作为验证结果的真集数据，但我这里所举的例子有些保守，把它设置为truth=false了，大家不必效仿，假如你没太大的“洁癖”把它设置为true都是没问题的（这也是GATK最佳实践的一般做法）。</p>
<p>1000G，千人基因组计划（1000 genomes project）质控后的变异数据，目前也是第三期，一共包含了2504个人的数据。通常来说质控后，它包含的绝大部分都是真实的变异，但由于没办法做全面的实验验证，并不能排除含有少部分假阳的结果。所以模型训练时给的权重虽然比较高——prior=10(likelihood为0.9)，但是一般就不作为模型验证的真集数据了，即truth=false。</p>
<p>dbSNP。说到dbSNP，这是一个绝对不可以作为训练集位点的数据——太脏了，为什么这么说呢？因为，dbSNP收集的数据，实际都是研究者们发表了相关文章提交上来的变异，这些变异很多是没做过严格验证的，很多甚至还是假的，在没被反复验证之前，是不可信的。因此，不会把它们作为模型的训练集，更不会把它作为真集看待（training=false,truth=false），权重也一般设置得很低，比如这里是prior=2（差不多才0.37）。dbSNP的唯一作用就是用于标注我们的变异集中哪些是已经在其它研究中出现过的——即属于已经被发现过的（已知）变异，给这些已知的变异位点标上RS id。</p>
<h3 id="Indel变异数据集"><a href="#Indel变异数据集" class="headerlink" title="Indel变异数据集"></a>Indel变异数据集</h3><p>Mills，对于Indel来说能正在算得上真集的并不多，Mills_and_1000G_gold_standard.indels.hg38.vcf算是其中一个，并被专门做过验证。但其实Indel并不那么容易验证，很多时候也是挑一些比较容易验证的结果。但不管如何，这是目前最佳的一个！所以权重各方面也都设置的比较高，比如prior=12，并且truth=true。</p>
<p>dbSNP，这个就和上面SNP模式下的作用是一样的。不过假如这一步对Indel进行VQSR的VCF数据是顺着上面SNP VQSR后下来的话，那么这个dbSNP的参数可以省略，因为已知变异的标注已经在SNP model下做好了。</p>
<h2 id="VQSR的原理"><a href="#VQSR的原理" class="headerlink" title="VQSR的原理"></a>VQSR的原理</h2><p><img src="/2022/01/25/WES06/01.png" alt="From: 黄树嘉"></p>
<h2 id="VQSR使用方法"><a href="#VQSR使用方法" class="headerlink" title="VQSR使用方法"></a>VQSR使用方法</h2><h3 id="VariantRecalibrator"><a href="#VariantRecalibrator" class="headerlink" title="VariantRecalibrator"></a>VariantRecalibrator</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">SNP</span></span><br><span class="line">gatk VariantRecalibrator \</span><br><span class="line">   -R ~/WES/ref/hg38.fna \</span><br><span class="line">   -V ~/WES/mutation/raw.vcf \</span><br><span class="line">   --resource:hapmap,known=false,training=true,truth=true,prior=15.0 ~/WES/gatk_resource_bundle/hg38/hapmap_3.3.hg38.ncbi.vcf \</span><br><span class="line">   --resource:omni,known=false,training=true,truth=false,prior=12.0 ~/WES/gatk_resource_bundle/hg38/1000G_omni2.5.hg38.ncbi.vcf \</span><br><span class="line">   --resource:1000G,known=false,training=true,truth=false,prior=10.0 ~/WES/gatk_resource_bundle/hg38/1000G_phase1.snps.high_confidence.hg38.ncbi.vcf \</span><br><span class="line">   --resource:dbsnp,known=true,training=false,truth=false,prior=2.0 ~/WES/gatk_resource_bundle/hg38/dbsnp_146.hg38.ncbi.vcf \</span><br><span class="line">   -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR \</span><br><span class="line">   --mode SNP \</span><br><span class="line">   -O ~/WES/mutation/VQSR/SNP.recal \</span><br><span class="line">   --tranches-file ~/WES/mutation/VQSR/SNP.tranches \</span><br><span class="line">   --rscript-file ~/WES/mutation/VQSR/SNP.plots.R</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">Indel</span></span><br><span class="line">gatk VariantRecalibrator \</span><br><span class="line">   -R ~/WES/ref/hg38.fna \</span><br><span class="line">   -V ~/WES/mutation/raw.vcf \</span><br><span class="line">   --resource:mills,known=false,training=true,truth=true,prior=12.0 ~/WES/gatk_resource_bundle/hg38/Mills_and_1000G_gold_standard.indels.hg38.ncbi.vcf \</span><br><span class="line">   --resource:ddbsnp,known=true,training=false,truth=false,prior=2.0 ~/WES/gatk_resource_bundle/hg38/dbsnp_146.hg38.ncbi.vcf \</span><br><span class="line">   -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR \</span><br><span class="line">   --mode INDEL \</span><br><span class="line">   -O ~/WES/mutation/VQSR/Indel.recal \</span><br><span class="line">   --tranches-file ~/WES/mutation/VQSR/Indel.tranches \</span><br><span class="line">   --rscript-file ~/WES/mutation/VQSR/Indel.plots.R</span><br></pre></td></tr></table></figure>



<h3 id="ApplyVQSR"><a href="#ApplyVQSR" class="headerlink" title="ApplyVQSR"></a>ApplyVQSR</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">SNP</span></span><br><span class="line">gatk ApplyVQSR \</span><br><span class="line">   -R ~/WES/ref/hg38.fna \</span><br><span class="line">   -V ~/WES/mutation/raw.vcf \</span><br><span class="line">   -O ~/WES/mutation/VQSR/VQSR.SNP.vcf \</span><br><span class="line">   --truth-sensitivity-filter-level 99.0 \</span><br><span class="line">   --tranches-file ~/WES/mutation/VQSR/SNP.tranches \</span><br><span class="line">   --recal-file ~/WES/mutation/VQSR/SNP.recal \</span><br><span class="line">   --mode SNP</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">Indel</span></span><br><span class="line">gatk ApplyVQSR \</span><br><span class="line">   -R ~/WES/ref/hg38.fna \</span><br><span class="line">   -V ~/WES/mutation/raw.vcf \</span><br><span class="line">   -O ~/WES/mutation/VQSR/VQSR.Indel.vcf \</span><br><span class="line">   --truth-sensitivity-filter-level 99.0 \</span><br><span class="line">   --tranches-file ~/WES/mutation/VQSR/Indel.tranches \</span><br><span class="line">   --recal-file ~/WES/mutation/VQSR/Indel.recal \</span><br><span class="line">   --mode INDEL</span><br></pre></td></tr></table></figure>

<p>让我们看以下变异位点数量：</p>
<p><img src="/2022/01/25/WES06/02.png"></p>
<p>这个项目本身是外显子测序，再加上样本数量和测序深度都不大，因此数据量本身就小。上图也表面一共就1000个变异，远远达不到训练模型所需要的至少5000个位点的要求。所以不能通过VQSR的方法来对其进行过滤。</p>
<h1 id="Hard-filters"><a href="#Hard-filters" class="headerlink" title="Hard-filters"></a>Hard-filters</h1><p>使用VQSR一是要求我们有可信度高的变异数据集，二是要求我们新测序的结果中有足够多的变异用于模型训练。如果未能达到上述要求，就不得不选择硬过滤的方式，即人为设定若干个指标的阈值，将不满足阈值条件的变异采用一刀切的方式排除掉。通常采取硬过滤使用的是gatk SelectVariants工具，它采用了VQSR所用的6个指标，这些指标都属于VCF的INFO字段（关于VCF文件的说明需要新开一坑），包括：</p>
<ul>
<li>QualByDepth（QD）</li>
<li>FisherStrand (FS)</li>
<li>StrandOddsRatio (SOR)</li>
<li>RMSMappingQuality (MQ)</li>
<li>MappingQualityRankSumTest (MQRankSum)</li>
<li>ReadPosRankSumTest (ReadPosRankSum)</li>
</ul>
<p>那么如何设定合适的阈值呢？</p>
<p>以QualByDepth（QD）为例。首先，什么是QD？QD=Qual/Allele Depth(AD)，即变异质量值除以覆盖深度，即对变异质量的标准化。因为每一个变异的read都对Qual值做出了贡献，测序深度越大其Qual值一般也越大，若不对其进行标准化，质控指标则会因局部深度不均匀而产生偏差。</p>
<p>以下是一个多样本VCF的例子：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1     1429249 .       C       T       1044.77  .  .  GT:AD:DP:GQ:PL  0/1:48,15:63:99:311,0,1644  0/0:47,0:47:99:392,0,0  1/1:0,76:76:99:3010,228,0</span><br></pre></td></tr></table></figure>

<p>我们可以看到这个变异位点一共有三个样本，其中第一个是杂合变异(GT=0/1)，第二个一个是纯合非变异(GT=0/0)，最后一个是纯合变异(GT=1/1)。其覆盖深度分别为63、47和76。因此这个位点的QD值等于质量值除以另外两个变异样本的覆盖深度：</p>
<p><code>QD=QUAL/AD=1429249/(63+76)=7.516</code></p>
<p>变异位点的QD值越高，其可信度也就越高。那么这个值大于多少，我们才在过滤时判断为真变异呢？简单来说就是一个可信的高深度数据进行VQSR，然后绘出各个指标好坏变异的密度分布图，根据密度分布图来设置阈值。人类的指标阈值就是根据GIAB数据库NA12878的高深度数据进行计算获得的。</p>
<p>最后还会通过计算变异位点Ti/Tv值来检验质控结果。Ti/Tv值是物种在与自然相互作用和演化过程中在基因组上留下来的一个统计标记，具有一定的稳定性。Ti是指嘧啶取代嘧啶或嘌呤取代嘌呤，称为转换；Tv指嘌呤和嘧啶之间的相互取代，称为颠换。如图：</p>
<p><img src="/2022/01/25/WES06/03.png"></p>
<p>对于人来说，全基因组的Ti/Tv在2.1左右，外显子区域在3.0左右，新发生的变异在1.5左右。</p>
<p>详细说明可以参考<a href="https://zhuanlan.zhihu.com/p/34878471">这篇文章</a>。</p>
<p>过滤之前需要先通过gatk SelectVariants的<code>-selectType</code>参数来将VC区分为SNP和Indel这两个不同的变异类型来进行，因为它们有些阈值是不同的，需要区别对待。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gatk SelectVariants \</span><br><span class="line">	-R ~/WES/ref/hg38.fna \</span><br><span class="line">	-V ~/WES/mutation/raw.vcf \</span><br><span class="line">	-select-type SNP \</span><br><span class="line">	-O ~/WES/mutation/raw_snps.vcf</span><br><span class="line">	</span><br><span class="line">gatk SelectVariants \</span><br><span class="line">	-R ~/WES/ref/hg38.fna \</span><br><span class="line">	-V ~/WES/mutation/raw.vcf \</span><br><span class="line">	-select-type INDEL \</span><br><span class="line">	-O ~/WES/mutation/raw_indels.vcf</span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">过滤SNP</span></span><br><span class="line">gatk VariantFiltration \</span><br><span class="line">	-R ~/WES/ref/hg38.fna \</span><br><span class="line">	-V ~/WES/mutation/raw_snps.vcf \</span><br><span class="line">	--filter-expression &quot;QD &lt; 2.0 || MQ &lt; 40.0 || FS &gt; 60.0 || SOR &gt; 3.0 || MQRankSum &lt; -12.5 || ReadPosRankSum &lt; -8.0&quot; \</span><br><span class="line">	--filter-name &quot;my_filter&quot; \</span><br><span class="line">	-O ~/WES/mutation/hard_filters/snp.filter.vcf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">过滤Indel</span></span><br><span class="line">gatk VariantFiltration \</span><br><span class="line">	-R ~/WES/ref/hg38.fna \</span><br><span class="line">	-V ~/WES/mutation/raw_indels.vcf \</span><br><span class="line">	--filter-expression &quot;QD &lt; 2.0 || FS &gt; 200.0 || SOR &gt; 10.0 || MQRankSum &lt; -12.5 || ReadPosRankSum &lt; -8.0&quot; \</span><br><span class="line">	--filter-name &quot;my_filter&quot; \</span><br><span class="line">	-O ~/WES/mutation/hard_filters/indel.filter.vcf</span><br></pre></td></tr></table></figure>



<p>参考文献：</p>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/34878471">GATK4.0和全基因组数据分析实践（下）</a></li>
<li><a href="https://gatk.broadinstitute.org/hc/en-us/articles/4414586833179-VariantRecalibrator">GATK VariantRecalibrator</a></li>
<li><a href="https://gatk.broadinstitute.org/hc/en-us/articles/4409924805147-ApplyVQSR">GATK ApplyVQSR</a></li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>WES</category>
      </categories>
  </entry>
  <entry>
    <title>变异注释</title>
    <url>/2022/02/06/WES07/</url>
    <content><![CDATA[<p>今天来学习DNA-seq下游分析的第三个内容<code>Annotation</code>。</p>
<ul>
<li>Call variants</li>
<li>Filter variants</li>
<li><strong>Annotation</strong></li>
</ul>
<p>得到新的变异位点后，我们希望了解这个位点存在于哪个基因？是有义突变还是无义突变？是否引起了编码氨基酸的变化？等等。一般使用ANNOVAR对过滤后的变异位点进行功能注释。</p>
<span id="more"></span>

<h1 id="annovar软件的获取"><a href="#annovar软件的获取" class="headerlink" title="annovar软件的获取"></a>annovar软件的获取</h1><p>annovar采用perl语言编写，因为linux出厂自带了perl，因此直接下载解压后就可以运行了。它需要使用带edu、ac或gov后缀的邮箱进行注册后才能下载。分享一个<a href="http://mail.mjj.edu.ge/">临时教育邮箱</a>。</p>
<p>下载annovar并解压，包含以下文件：</p>
<ul>
<li>example：存放示例文件。</li>
<li>humandb：存放annovar软件自带的注释数据库，也可根据自己的研究需要自行下载。</li>
<li>annotate_variation.pl：主程序。下载数据库；可使用三种方式注释变异。</li>
<li>coding_change.pl：判断蛋白质的序列是否发生变化。</li>
<li>convert2annovar.pl：将其他文本格式（如vcf）转换为annovar可识别格式。</li>
<li>retrieve_seq_from_fasta.pl：建立其他的转录本。自带数据库只包含人类hg19的转录本。</li>
<li>table_annovar.pl：一次完成三种不同方式的注释。</li>
<li>variants_reduction.pl：定制过滤注释流程。</li>
</ul>
<h1 id="annovar的三种注释方式"><a href="#annovar的三种注释方式" class="headerlink" title="annovar的三种注释方式"></a>annovar的三种注释方式</h1><h2 id="Gene-based-annotation"><a href="#Gene-based-annotation" class="headerlink" title="Gene-based annotation"></a>Gene-based annotation</h2><p>基于基因的注释，揭示变异与已知基因直接的关系以及对其产生的功能性影响。一般人做到这里就结束了，因为信息量足够了。运行后会生成三个文件：<code>variant_function</code>、<code>exonic_variant_function</code>和<code>log</code>文件。</p>
<p>主要关注exonic_variant_function，里面记录每个变异位点的functional consequences，包括nonsynonymous SNV, synonymous SNV, frameshift insertion, frameshift  deletion, nonframeshift insertion, nonframeshift deletion, frameshift  block substitution, nonframshift block substitution。通常，我们会关心<code>nonsynonymous SNV</code>非同义替换，因为它表明单核苷酸的变异引起了氨基酸的改变。</p>
<p>但是，这样还是不够的，因为虽然造成了氨基酸的变异，但是这并不意味着这个突变是有害的。</p>
<p>首先要做的就是判断这个位点是否报道过，是否通过实验证实了这个位点是致病突变。然后可以看看这个突变位点在一系列健康人群数据库里是否也被发现过，一般来说健康人群很高的位点，通常就不会是致病位点。</p>
<h2 id="Region-based-annotation"><a href="#Region-based-annotation" class="headerlink" title="Region-based annotation"></a>Region-based annotation</h2><p>鉴定基因组特定区域的突变。例如它是否落在已知的基因组保守区域。基于区域的注释所需的数据库一般由UCSC提供。输出文件以数据库名结尾。</p>
<h2 id="Filter-based-annotation"><a href="#Filter-based-annotation" class="headerlink" title="Filter-based annotation"></a>Filter-based annotation</h2><p>基于筛选的注释。使用不同的过滤数据库，可以给出这个变异的一系列信息。如在全基因组中的变异频率，可使用1000g、kaviar等数据库；在全外显子基因组中的变异频率，可使用exac03、esp6500siv2等数据库；在孤立的或者低代表人群中的变异频率，可使用ajews等数据库。</p>
<p>这个使用频率非常高，而且通常是结合多个数据库信息一起过滤。一般的思路是，找到某个基因被注释到外显子区域的nonsynonymous突变，然后又被clinvar数据库记录，则说明找到了有证据支持的致病位点。</p>
<h1 id="输入文件"><a href="#输入文件" class="headerlink" title="输入文件"></a>输入文件</h1><p>annovar的输入文件为简单文本格式文件，前五列分别为<code>染色体号</code>、<code>突变位点起始位置</code>、<code>突变位点结束位置</code>、<code>该位点在参考基因组上的碱基</code>和<code>该位点的突变碱基</code>，其他列可有可无。使用以下命令，可以将gatk得到的vcf文件转换为annovar所需文本格式：</p>
<figure class="highlight perl"><table><tr><td class="code"><pre><span class="line">perl convert2annovar.pl \</span><br><span class="line">     -<span class="keyword">format</span> vcf4 input.vcf \</span><br><span class="line">     -outfile input.avinput</span><br></pre></td></tr></table></figure>

<p>不过，因为VCF文件格式的普遍性，现在的table_annovar.pl已经可以支持VCF文件了，只需加上<code>-vcfinput</code>参数就行了。</p>
<h1 id="数据库下载"><a href="#数据库下载" class="headerlink" title="数据库下载"></a>数据库下载</h1><p>Annovar的注释主要依赖于数据库，因此在进行分析之前，应将所需的数据库下载到humandb文件夹中，下载的命令如下：</p>
<figure class="highlight perl"><table><tr><td class="code"><pre><span class="line">perl annotate_variation.pl \</span><br><span class="line">     -downdb \</span><br><span class="line">     -webfrom annovar \</span><br><span class="line">     -buildver hg38 \</span><br><span class="line">     refGene \</span><br><span class="line">     humandb/</span><br></pre></td></tr></table></figure>

<ul>
<li>-buildver：参考基因组的版本。</li>
<li>-webfrom annovar：从annovar库中对应名称的数据库；如果<a href="http://annovar.openbioinformatics.org/en/latest/user-guide/download/">annovar库</a>中没有，则不用指定该选项，会自动从UCSC中下载。</li>
<li>refGene：数据库名称。</li>
<li>humandb/：指定数据库存放的文件夹。</li>
</ul>
<p>三种不同方式注释常用到的数据包括：</p>
<ul>
<li>gene-based：refGene等。</li>
<li>region-based：cytoBand等。</li>
<li>filter-based：1000g2015aug (6 data sets)、exac03、ljb26_all、clinvar_20210123、avsnp150等。</li>
</ul>
<p>refGene：FASTA sequences for all annotated transcripts in RefSeq Gene。</p>
<p>exact03：ExAC 65000 exome allele frequency data for ALL, AFR (African), AMR  (Admixed American), EAS (East Asian), FIN (Finnish), NFE (Non-finnish  European), OTH (other), SAS (South Asian)). version 0.3. Left  normalization done.</p>
<p>dbnsfp42c：whole-exome SIFT, PolyPhen2 HDIV, PolyPhen2 HVAR, LRT, MutationTaster,  MutationAssessor, FATHMM, PROVEAN, MetaSVM, MetaLR, VEST, M-CAP, CADD,  GERP++, DANN, fathmm-MKL, Eigen, GenoCanyon, fitCons, PhyloP and SiPhy  scores from dbNSFP version 4.2c.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">gene-based数据库refGene</span></span><br><span class="line">perl annotate_variation.pl -downdb -buildver hg38 -webfrom annovar refGene humandb/</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">filter-based数据库exac03、dbnsfp42c</span></span><br><span class="line">perl annotate_variation.pl -downdb -buildver hg38 -webfrom annovar exac03 ~/annovar/humandb</span><br><span class="line">perl annotate_variation.pl -downdb -buildver hg38 -webfrom annovar dbnsfp42c ~/annovar/humandb</span><br></pre></td></tr></table></figure>

<p>注：所有代码都在annovar文件夹下运行。</p>
<p>注释数据库的说明：</p>
<ul>
<li>refGene：FASTA sequences for all annotated transcripts in RefSeq Gene。</li>
<li>exact03：ExAC 65000 exome allele frequency data for ALL, AFR (African), AMR  (Admixed American), EAS (East Asian), FIN (Finnish), NFE (Non-finnish  European), OTH (other), SAS (South Asian)). version 0.3. Left  normalization done.</li>
<li>dbnsfp42c：whole-exome SIFT, PolyPhen2 HDIV, PolyPhen2 HVAR, LRT, MutationTaster,  MutationAssessor, FATHMM, PROVEAN, MetaSVM, MetaLR, VEST, M-CAP, CADD,  GERP++, DANN, fathmm-MKL, Eigen, GenoCanyon, fitCons, PhyloP and SiPhy  scores from dbNSFP version 4.2c.</li>
</ul>
<h1 id="变异注释"><a href="#变异注释" class="headerlink" title="变异注释"></a>变异注释</h1><p>准备好输入文件和数据库后，就可以进行注释了。</p>
<p>可以使用annotate_variation.pl以其中一种方式进行注释。三种不同方式的命令如下：</p>
<figure class="highlight perl"><table><tr><td class="code"><pre><span class="line">perl annotate_variation.pl -geneanno -dbtype refGene -buildver hg19 example/ex1.avinput humandb/</span><br><span class="line"></span><br><span class="line">perl annotate_variation.pl -regionanno -dbtype cytoBand -buildver hg19 example/ex1.avinput humandb/ </span><br><span class="line"></span><br><span class="line">perl annotate_variation.pl -filter -dbtype exac03 -buildver hg19 example/ex1.avinput humandb/</span><br></pre></td></tr></table></figure>

<p>也可以使用table_annovar.pl同时完成三种方式的注释，当然它也通过调用主程序annotate_variation.pl实现的。命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">perl table_annovar.pl \</span><br><span class="line">     input.vcf \</span><br><span class="line">     humandb/ \</span><br><span class="line">     -vcfinput \</span><br><span class="line">     -buildver hg38 \</span><br><span class="line">     -out output \</span><br><span class="line">     -remove \</span><br><span class="line">     -csvout \</span><br><span class="line">     -polish \</span><br><span class="line">     -protocol refGene,cytoBand,1000g2014oct_eur,1000g2014oct_afr,exac03,ljb26_all,clinvar_20140929,snp138 \</span><br><span class="line">     -operation g,r,f,f,f,f,f,f</span><br></pre></td></tr></table></figure>

<ul>
<li>-out：指定输出文件前缀。</li>
<li>-remove：删掉中间文件。</li>
<li>-csvout：输出CSV文件。不加这个参数则输出txt文件。</li>
<li>-polish：</li>
<li>-protocal：数据库的名称。</li>
<li>-operation：对应数据库的类型。g，gene-based；r，region-based；f，filter-based。需按前面数据库顺序一一对应。</li>
</ul>
<p>实际操作：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">需要先将硬过滤生成的SNP和Indel的VCF合并</span></span><br><span class="line">bgzip -c indel.filter.vcf &gt; indel.filter.vcf.bgzip.gz</span><br><span class="line">bgzip -c snp.filter.vcf &gt; snp.filter.vcf.bgzip.gz</span><br><span class="line">bcftools index snp.filter.vcf.bgzip.gz </span><br><span class="line">bcftools index indel.filter.vcf.bgzip.gz </span><br><span class="line">bcftools concat -a snp.filter.vcf.bgzip.gz indel.filter.vcf.bgzip.gz -o filter.vcf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">VCF命名变为UCSC命名风格，因为数据库染色体的命名方式都是这样</span></span><br><span class="line">cthreepo --infile filter.vcf --id_from rs --id_to uc --format vcf -a GCF_000001405.39 --outfile filter_ucsc.vcf</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">如果想得到csv格式变异注释文件，需先将vcf转换为avinput格式</span></span><br><span class="line">perl convert2annovar.pl \</span><br><span class="line">     -format vcf4 ~/WES/mutation/hard_filters/filter_ucsc.vcf \</span><br><span class="line">     -outfile ~/WES/mutation/hard_filters/filter_ucsc.avinput</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">注释：得到.CSV注释文件</span></span><br><span class="line">perl table_annovar.pl ~/WES/mutation/hard_filters/filter_ucsc.avinput humandb/ -buildver hg38 -out ~/WES/annotation/output -csvout -remove -polish -protocol refGene,exac03,dbnsfp42c -operation g,f,f</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">注释：得到txt和vcf格式注释文件</span></span><br><span class="line">perl table_annovar.pl ~/WES/mutation/hard_filters/filter_ucsc.vcf humandb/ -vcfinput -buildver hg38 -out output -remove -protocol refGene,exac03,dbnsfp42c -operation g,f,f</span><br></pre></td></tr></table></figure>

<p>以.csv注释文件为例：</p>
<p><img src="/2022/02/06/WES07/01.png"></p>
<p>前五列为输入文件的内容，包括染色体、起始位置、终止位置、参考基因位点、变异位点。后面几列为注释内容，安装输入的注释数据库排列。其中，refGene包含Func.refGene, Gene.refGene, GeneDetail.refGene, ExonicFunc.refGene, AAChange.refGene；ExAC包含变异位点在6个人种的变异频率；dbnsfp42c注释了non-synonymous SNP的预测分数，包括SIFT scores, PolyPhen2 HDIV scores, PolyPhen2 HVAR scores, LRT scores, MutationTaster scores等。更多内容可参考<a href="https://brb.nci.nih.gov/seqtools/colexpanno.html#dbnsfp">这里</a>。</p>
<p>除了命令行工具外，软件作者还提供了网页工具<a href="https://wannovar.wglab.org/">wAnnovar</a>。</p>
<p>参考文章：</p>
<ol>
<li><a href="https://www.nature.com/articles/nprot.2015.105">Genomic variant annotation and prioritization with ANNOVAR and wANNOVAR</a></li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>WES</category>
      </categories>
  </entry>
  <entry>
    <title>参考基因组</title>
    <url>/2022/01/10/%E5%8F%82%E8%80%83%E5%9F%BA%E5%9B%A0%E7%BB%84/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>–为什么需要参考基因组？</p>
<hr>
<p>基因组分析的中心法则：所有的基因组分析都是（应该）基于一个正常的参考序列。</p>
<span id="more"></span>

<p>为什么？让我们思考一个更简单但是相类似的问题。现在我们知道有来源于同一普通古语的三种现代表达：</p>
<ol>
<li>The quick brown f<strong>a</strong>x jumped over the lazy dog<strong>e</strong>.</li>
<li>The quick <strong>_</strong> fox jump<strong>s</strong> over the lazy dog<strong>e</strong>. </li>
<li>The quick brown fox jump<strong>s</strong> over the lazy <strong>brown</strong> dog. </li>
</ol>
<p>我们希望有一种方法能找出他们的差异，但又不偏向于其中任何一个，并且当我们再次碰到新句子时，这种方法也足够可靠地发现其中可能的突变。因此我们创建了一个包含它们所有共性的杂合句：</p>
<p>The quick brown fox jumped over the lazy dog<strong>e</strong>.</p>
<p>我们能够使用这个句子作为一个共同的参考坐标系，并将每个突变句子的差异标记在上面：</p>
<p>第一句：第4个词发生o→a替换；第9个词e缺失。</p>
<p>第二句：第3个词缺失；第5个词发生ed→s替换；第9个词e增加。</p>
<p>第三句：第5个词发生ed→s替换；第3个词复制后插到第8个词后面。</p>
<p>很明显，这不是一个完美的方法。并且，它没有给出一个祖先句，因为我们怀疑“dog”不是“狗”最初的拼写方式，我们也不确定原始的时态是什么（jumps OR jumped）。但是，它使我们从不同差异中区分出，哪种差异是常态。</p>
<p>刚开始用于创建参考的句子越多、越具有代表性，未来我们在遇到变异时就越能更准确地去定义它。</p>
<p>这正是我们在使用参考基因组时所做的：相较于试着去描绘不同基因组序列之间的差异（事实上当序列大于2条时这将变得十分困难），我们不如描绘它们与同一个标准相比时的差异。基于这点，我们只需去证明哪些变异是这些序列所共有的，哪些变异是独属于一个个体，而这将变得容易得多。</p>
<p>所以通常我们应该使用谁的基因组作为标准？理论上，任何一个基因组都能被用作参考基因组。但是，当参考基因组越能代表我们可能想研究的最广泛的群体，分析的质量和灵敏度也就越高。因此，参考基因组序列的每一个片段都应该表现为在可利用的个体基因组群中最常见的序列。据此产生的参考基因组是作为原型存在的杂合体，所以任何一个个体的基因组也都不具备该参考基因组一模一样的序列。</p>
<p>此外，值得注意的是，目前所有的参考基因组都是单倍体，这意味着它们仅能代表染色体的其中一条。最直接的后果就是，在诸如人类这样的二倍体生物中，对于处于杂合状态位点而言，标准序列的选择很大程度上的随机的。而这在多数植物中表现得更加明显，诸如小麦、草莓之类的它们具有更高倍数的染色体。虽然使用图示是可以将参考基因组的不同染色体表示出来，但是目前几乎没有合适的分析工具来处理这样表示的数据。更多讨论可详见这篇<a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-015-0587-3">文章</a>。</p>
<p>–以上内容来自<a href="https://gatk.broadinstitute.org/hc/en-us/articles/360035891071">译文</a>。</p>
<h1 id="参考基因组文件和注释文件"><a href="#参考基因组文件和注释文件" class="headerlink" title="参考基因组文件和注释文件"></a>参考基因组文件和注释文件</h1><p>参考基因组文件一般是以.fa结尾的文本文件。在生物信息学中，FASTA是一种基于文本的、用于表示核苷酸序列或氨基酸序列的格式。FASTA以序列表示和序列作为一个基本单元，一个单元包括两行：</p>
<ul>
<li><p>第一行是以 &gt; 开头的文字说明，用于序列标记，标识需具有唯一性。</p>
</li>
<li><p>第二行是由A\T\C\G四个字母组成的碱基序列。</p>
</li>
</ul>
<p>以人类参考基因组hg38为例：</p>
<p><img src="/2022/01/10/%E5%8F%82%E8%80%83%E5%9F%BA%E5%9B%A0%E7%BB%84/05.png"></p>
<p>值得注意的是：由于FASTA除序列外的头信息没有被严格地限制格式，因此不同数据库中的参考基因组其都信息都有差别。在使用程序进行分析时可能会出现错误。</p>
<p>由于参考基因组文件是一段无序的序列，因此需要注释文件对其进行注释，来告诉我们某一段所对应的基因结构，包括Gene、CDS、mRNA、5’UTR、3’UTR、exon等。</p>
<p>基因注释文件较多，其中GFF和GTF是最常用的基因注释文件。其中GTF是GFF的扩展。前八个字段，GTF与GFF相同；但GTF还包含可选字段：5’UTR、3’UTR、inter、inter_CNS、intro_CNS。</p>
<table>
<thead>
<tr>
<th align="center"><strong>前八个字段</strong></th>
<th align="center"><strong>含义</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">seq_id</td>
<td align="center">序列编号。一般为chr编号。</td>
</tr>
<tr>
<td align="center">source</td>
<td align="center">注释来源。一般为数据库或注释机构。</td>
</tr>
<tr>
<td align="center">type</td>
<td align="center">注释信息类型。如Gene、cDNA、CDS、mRNA等。</td>
</tr>
<tr>
<td align="center">start</td>
<td align="center">该基因或转录本在参考序列的起始位置。</td>
</tr>
<tr>
<td align="center">end</td>
<td align="center">该基因或转录本在参考序列的结束位置。</td>
</tr>
<tr>
<td align="center">score</td>
<td align="center">该行序列相似性的分数。</td>
</tr>
<tr>
<td align="center">strand</td>
<td align="center">+表示正链，-表示负链。</td>
</tr>
<tr>
<td align="center">phase</td>
<td align="center">仅对CDS类型有效。表示读码框起始位置，有效值为0、1、2。</td>
</tr>
</tbody></table>
<p>以人类参考基因组hg38的GFF注释文件为例：</p>
<p><img src="/2022/01/10/%E5%8F%82%E8%80%83%E5%9F%BA%E5%9B%A0%E7%BB%84/04.png"></p>
<h1 id="如何获取参考基因组？"><a href="#如何获取参考基因组？" class="headerlink" title="如何获取参考基因组？"></a>如何获取参考基因组？</h1><p>如何组装参考基因组这不是我们应该考虑的事，至少目前我们还不具备de nova所需的硬件条件。因此，我们主要需要了解如何从公共数据库中获取我们需要的参考基因组及其注释文件。</p>
<p>数据库的种类有很多，其中主要基因组数据库如下：</p>
<table>
<thead>
<tr>
<th>数据库</th>
<th>网址</th>
<th>包含物种</th>
</tr>
</thead>
<tbody><tr>
<td>Ensembl</td>
<td><a href="http://www.ensembl.org/index.html">http://www.ensembl.org/index.html</a></td>
<td>人类、鼠、脊椎动物和真核生物</td>
</tr>
<tr>
<td>Ensembl Genomes</td>
<td><a href="http://wnsemblgenomes.org/">http://wnsemblgenomes.org</a></td>
<td>细菌、原生生物、真菌、植物及无脊椎动物</td>
</tr>
<tr>
<td>NCBI</td>
<td><a href="https://www.ncbi.nlm.nih.gov/genome">https://www.ncbi.nlm.nih.gov/genome</a></td>
<td>综合</td>
</tr>
<tr>
<td>UCSC</td>
<td><a href="http://genome.ucsc.edu/index.html">http://genome.ucsc.edu/index.html</a></td>
<td>脊椎动物</td>
</tr>
<tr>
<td>CAMERA</td>
<td><a href="http://camera.calit2.net/index.php">http://camera.calit2.net/index.php</a></td>
<td>微生物</td>
</tr>
<tr>
<td>The 1000 Genomes Project</td>
<td><a href="http://www.1000genomes.org/">http://www.1000genomes.org</a></td>
<td>千人基因组</td>
</tr>
<tr>
<td>Personal Genome Project</td>
<td><a href="http://www.personalgenomes.org/">http://www.personalgenomes.org</a></td>
<td>人类个体</td>
</tr>
<tr>
<td>GDB</td>
<td><a href="http://www.gdb.org/">http://www.gdb.org</a></td>
<td>人类</td>
</tr>
<tr>
<td>RGD</td>
<td>http:/rgd.mcw.edu</td>
<td>鼠</td>
</tr>
<tr>
<td>EcoCye</td>
<td><a href="http://ecocye.org/">http://ecocye.org</a></td>
<td>大肠杆菌</td>
</tr>
<tr>
<td>Flybase</td>
<td><a href="http://flybase.org/">http://flybase.org</a></td>
<td>果蝇</td>
</tr>
<tr>
<td>ZFIN</td>
<td><a href="http://zfin.org/">http://zfin.org</a></td>
<td>斑马鱼</td>
</tr>
<tr>
<td>TAIR</td>
<td><a href="http://www.arabidopsis.org/">http://www.arabidopsis.org</a></td>
<td>拟南芥</td>
</tr>
<tr>
<td>maizegdb</td>
<td><a href="http://www.maizegdb.org/">http://www.maizegdb.org</a></td>
<td>玉米</td>
</tr>
<tr>
<td>BRAD</td>
<td><a href="http://brassicadb.org/brad">http://brassicadb.org/brad</a></td>
<td>芸薹属</td>
</tr>
<tr>
<td>plantGDB</td>
<td><a href="http://www.plantgdb.org/">http://www.plantgdb.org</a></td>
<td>植物</td>
</tr>
</tbody></table>
<p>以人类基因组为例，最为常用的三大数据库为NCBI、ENSEMBL和USCS，它们都提供了FTP协议来传输文件。对于FTP协议，我们可以通过浏览器自带的下载器进行下载，也可以通过命令行工具进行下载。常见的命令行工具如下：</p>
<table>
<thead>
<tr>
<th>命令工具</th>
<th>支持协议</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>wget</td>
<td>HTTP(S)、FTP</td>
<td>单线程</td>
</tr>
<tr>
<td>mwget</td>
<td>HTTP(S)、FTP</td>
<td>多线程</td>
</tr>
<tr>
<td>axel</td>
<td>HTTP(S)、FTP(S)</td>
<td>多线程、断电续传</td>
</tr>
<tr>
<td>aria2</td>
<td>HTTP(S)、FTP、BitTorrent、Metalink</td>
<td>多线程</td>
</tr>
</tbody></table>
<p>通常线程数越多，能够从FTP服务器获取的带宽也就越多，下载速度就越快，当然占用的本地资源就越大。</p>
<p>下面以axel为例下载NCBI上人类参考基因组及其注释文件。</p>
<p>安装Axel：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install axel</span><br></pre></td></tr></table></figure>

<p>用法：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">axel [options] url1 [url2] [url...]</span><br></pre></td></tr></table></figure>

<p>选项：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--max-speed=x , -s x        最高速度x</span><br><span class="line">--num-connections=x , -n x   连接数x</span><br><span class="line">--output=f , -o f           下载为本地文件f</span><br><span class="line">--search[=x] , -S [x]       搜索镜像</span><br><span class="line">--header=x , -H x           添加头文件字符串x（指定 HTTP header）</span><br><span class="line">--user-agent=x , -U x       设置用户代理（指定 HTTP user agent）</span><br><span class="line">--no-proxy ， -N            不使用代理服务器</span><br><span class="line">--quiet ， -q               静默模式</span><br><span class="line">--verbose ，-v              更多状态信息</span><br><span class="line">--alternate ， -a           Alternate progress indicator</span><br><span class="line">--help ，-h                 帮助</span><br><span class="line">--version ，-V              版本信息</span><br></pre></td></tr></table></figure>

<p>打开<a href="https://www.ncbi.nlm.nih.gov/">NCBI</a>，选择gnome数据库，然后输入“human”进行搜索。</p>
<p><img src="/2022/01/10/%E5%8F%82%E8%80%83%E5%9F%BA%E5%9B%A0%E7%BB%84/01.png"></p>
<p>然后页面给出了Homo sapiens(human)的最新参考基因组及注释文件的链接，点击genome和GFF即可通过下载器下载我们需要的人类参考基因组及其注释文件。</p>
<p><img src="/2022/01/10/%E5%8F%82%E8%80%83%E5%9F%BA%E5%9B%A0%E7%BB%84/02.png"></p>
<p>但这里我选择右键复制其下载链接，并通过命令行工具axel进行下载。建议白天进行下载以避开国外使用的高峰期。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">axel -n 10 https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_genomic.fna.gz </span><br><span class="line">axel -n 10 https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.39_GRCh38.p13/GCF_000001405.39_GRCh38.p13_genomic.gff.gz</span><br></pre></td></tr></table></figure>

<p>-n为最大连接数。支持断点续传，只需将同一命令重输一篇即可。默认下载位置为当前文件夹，使用pwd命令即可查看当前文件夹位置。</p>
<p><img src="/2022/01/10/%E5%8F%82%E8%80%83%E5%9F%BA%E5%9B%A0%E7%BB%84/03.png"></p>
]]></content>
      <categories>
        <category>生物信息学</category>
      </categories>
  </entry>
  <entry>
    <title>hexo博客插入图片和视频</title>
    <url>/2022/01/07/%E5%9B%BE%E7%89%87&amp;%E8%A7%86%E9%A2%91%E6%8F%92%E5%85%A5/</url>
    <content><![CDATA[<p>在博客中插入视频和图片能让人通俗易懂，生动形象。下面是我找到的一些方法，主要介绍了本地图片和在线视频的插入方法。</p>
<span id="more"></span>

<h1 id="图片插入"><a href="#图片插入" class="headerlink" title="图片插入"></a>图片插入</h1><h2 id="插件安装"><a href="#插件安装" class="headerlink" title="插件安装"></a>插件安装</h2><p>因为hexo本身不支持通用的markdown图片插入语法，因此需要借助插件hexo-asset-image。</p>
<p>在站点目录执行如下脚本进行安装：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install hexo-asset-image --save</span><br></pre></td></tr></table></figure>

<h2 id="插件修正"><a href="#插件修正" class="headerlink" title="插件修正"></a>插件修正</h2><p>但这个插件有点bug，会导致转换出来的img的路径不对，因此需要手动定位修改。</p>
<p>具体原理和方法超出了我的认知。具体操作只需将下列代码替换到/node_modules/hexo-asset-image/index.js即可。替换前建议对index.js备份。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="meta">&#x27;use strict&#x27;</span>;</span><br><span class="line"><span class="keyword">var</span> cheerio = <span class="built_in">require</span>(<span class="string">&#x27;cheerio&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// http://stackoverflow.com/questions/14480345/how-to-get-the-nth-occurrence-in-a-string</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getPosition</span>(<span class="params">str, m, i</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> str.split(m, i).join(m).length;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> version = <span class="built_in">String</span>(hexo.version).split(<span class="string">&#x27;.&#x27;</span>);</span><br><span class="line">hexo.extend.filter.register(<span class="string">&#x27;after_post_render&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> config = hexo.config;</span><br><span class="line">  <span class="keyword">if</span>(config.post_asset_folder)&#123;</span><br><span class="line">        <span class="keyword">var</span> link = data.permalink;</span><br><span class="line">    <span class="keyword">if</span>(version.length &gt; <span class="number">0</span> &amp;&amp; <span class="built_in">Number</span>(version[<span class="number">0</span>]) == <span class="number">3</span>)</span><br><span class="line">       <span class="keyword">var</span> beginPos = getPosition(link, <span class="string">&#x27;/&#x27;</span>, <span class="number">1</span>) + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">       <span class="keyword">var</span> beginPos = getPosition(link, <span class="string">&#x27;/&#x27;</span>, <span class="number">3</span>) + <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// In hexo 3.1.1, the permalink of &quot;about&quot; page is like &quot;.../about/index.html&quot;.</span></span><br><span class="line">    <span class="keyword">var</span> endPos = link.lastIndexOf(<span class="string">&#x27;/&#x27;</span>) + <span class="number">1</span>;</span><br><span class="line">    link = link.substring(beginPos, endPos);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">var</span> toprocess = [<span class="string">&#x27;excerpt&#x27;</span>, <span class="string">&#x27;more&#x27;</span>, <span class="string">&#x27;content&#x27;</span>];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; toprocess.length; i++)&#123;</span><br><span class="line">      <span class="keyword">var</span> key = toprocess[i];</span><br><span class="line"> </span><br><span class="line">      <span class="keyword">var</span> $ = cheerio.load(data[key], &#123;</span><br><span class="line">        <span class="attr">ignoreWhitespace</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">xmlMode</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">lowerCaseTags</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="attr">decodeEntities</span>: <span class="literal">false</span></span><br><span class="line">      &#125;);</span><br><span class="line"></span><br><span class="line">      $(<span class="string">&#x27;img&#x27;</span>).each(<span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ($(<span class="built_in">this</span>).attr(<span class="string">&#x27;src&#x27;</span>))&#123;</span><br><span class="line">            <span class="comment">// For windows style path, we replace &#x27;\&#x27; to &#x27;/&#x27;.</span></span><br><span class="line">            <span class="keyword">var</span> src = $(<span class="built_in">this</span>).attr(<span class="string">&#x27;src&#x27;</span>).replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>);</span><br><span class="line">            <span class="keyword">if</span>(!<span class="regexp">/http[s]*.*|\/\/.*/</span>.test(src) &amp;&amp;</span><br><span class="line">               !<span class="regexp">/^\s*\//</span>.test(src)) &#123;</span><br><span class="line">              <span class="comment">// For &quot;about&quot; page, the first part of &quot;src&quot; can&#x27;t be removed.</span></span><br><span class="line">              <span class="comment">// In addition, to support multi-level local directory.</span></span><br><span class="line">              <span class="keyword">var</span> linkArray = link.split(<span class="string">&#x27;/&#x27;</span>).filter(<span class="function"><span class="keyword">function</span>(<span class="params">elem</span>)</span>&#123;</span><br><span class="line">                <span class="keyword">return</span> elem != <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">              &#125;);</span><br><span class="line">              <span class="keyword">var</span> srcArray = src.split(<span class="string">&#x27;/&#x27;</span>).filter(<span class="function"><span class="keyword">function</span>(<span class="params">elem</span>)</span>&#123;</span><br><span class="line">                <span class="keyword">return</span> elem != <span class="string">&#x27;&#x27;</span> &amp;&amp; elem != <span class="string">&#x27;.&#x27;</span>;</span><br><span class="line">              &#125;);</span><br><span class="line">              <span class="keyword">if</span>(srcArray.length &gt; <span class="number">1</span>)</span><br><span class="line">                srcArray.shift();</span><br><span class="line">              src = srcArray.join(<span class="string">&#x27;/&#x27;</span>);</span><br><span class="line">              $(<span class="built_in">this</span>).attr(<span class="string">&#x27;src&#x27;</span>, config.root + link + src);</span><br><span class="line">              <span class="built_in">console</span>.info&amp;&amp;<span class="built_in">console</span>.info(<span class="string">&quot;update link as:--&gt;&quot;</span>+config.root + link + src);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="built_in">console</span>.info&amp;&amp;<span class="built_in">console</span>.info(<span class="string">&quot;no src attr, skipped...&quot;</span>);</span><br><span class="line">            <span class="built_in">console</span>.info&amp;&amp;<span class="built_in">console</span>.info($(<span class="built_in">this</span>));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">      data[key] = $.html();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h2 id="图片插入-1"><a href="#图片插入-1" class="headerlink" title="图片插入"></a>图片插入</h2><p>执行代码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo n &quot;图片&amp;视频插入&quot;</span><br></pre></td></tr></table></figure>

<p>在站点的source/_posts会里生成图片&amp;视频插入.md的文本文件和一个同名的文件夹。</p>
<p><img src="/2022/01/07/%E5%9B%BE%E7%89%87&%E8%A7%86%E9%A2%91%E6%8F%92%E5%85%A5/02.png"></p>
<p>将需要插入这篇文章的图片放入文件夹。</p>
<p><img src="/2022/01/07/%E5%9B%BE%E7%89%87&%E8%A7%86%E9%A2%91%E6%8F%92%E5%85%A5/03.png"></p>
<p>md文档里的引用格式为</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">![<span class="string">jay</span>](<span class="link">jay.jpeg</span>) #方括号[]内添加图片描述，可忽略；圆括号（）内为图片相对地址，即图片文件名。</span><br></pre></td></tr></table></figure>

<p>效果如下：</p>
<p><img src="/2022/01/07/%E5%9B%BE%E7%89%87&%E8%A7%86%E9%A2%91%E6%8F%92%E5%85%A5/jay.jpeg" alt="jay"></p>
<h1 id="视频插入"><a href="#视频插入" class="headerlink" title="视频插入"></a>视频插入</h1><p>视频的插入与图片不同，需要在文档里插入一段html代码，这里以b站视频为例。</p>
<p>随意点开某个b站视频，然后选择分享，复制下面的的嵌入代码，粘贴到文档里。</p>
<p><img src="/2022/01/07/%E5%9B%BE%E7%89%87&%E8%A7%86%E9%A2%91%E6%8F%92%E5%85%A5/04.png"></p>
<p>嵌入代码：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">iframe</span> <span class="attr">src</span>=<span class="string">&quot;//player.bilibili.com/player.html?aid=800358811&amp;bvid=BV1Gy4y1q7ZS&amp;cid=257606677&amp;page=1&quot;</span> <span class="attr">scrolling</span>=<span class="string">&quot;no&quot;</span> <span class="attr">border</span>=<span class="string">&quot;0&quot;</span> <span class="attr">frameborder</span>=<span class="string">&quot;no&quot;</span> <span class="attr">framespacing</span>=<span class="string">&quot;0&quot;</span> <span class="attr">allowfullscreen</span>=<span class="string">&quot;true&quot;</span>&gt;</span> <span class="tag">&lt;/<span class="name">iframe</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>添加参数width和height，并设置为100%，使得视频页面布局能自适应。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;iframe src=&quot;//player.bilibili.com/player.html?aid=800358811&amp;bvid=BV1Gy4y1q7ZS&amp;cid=257606677&amp;page=1&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot; width=&quot;100%&quot; height=&quot;100%&quot;&gt; &lt;/iframe&gt;</span><br></pre></td></tr></table></figure>

<p>效果如下：</p>
<iframe src="//player.bilibili.com/player.html?aid=800358811&bvid=BV1Gy4y1q7ZS&cid=257606677&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true" width="100%" height="100%"> </iframe>



]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
</search>
